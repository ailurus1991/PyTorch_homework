{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器翻译的神经网络实现\n",
    "\n",
    "本节课我们讲述了利用编码器－解码器架构实现汉－英机器翻译。\n",
    "\n",
    "整个代码包括了数据预处理、编码器＋简单解码器以及编码器＋带有注意力机制的解码器三个部分组成。\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第VIII课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用到的包\n",
    "#from __future__ import unicode_literals, print_function, division\n",
    "# 进行系统操作，如io、正则表达式的包\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "#import time\n",
    "#import math\n",
    "\n",
    "#Pytorch必备的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as DataSet\n",
    "\n",
    "\n",
    "# 绘图所用的包\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 判断本机是否有支持的GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "#use_cuda = False\n",
    "# 即时绘图\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、数据准备\n",
    "\n",
    "从硬盘读取语料文件，进行基本的预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# 读取平行语料库\n",
    "# 这是人民日报语料库\n",
    "lines = open('data/chinese.txt', encoding = 'utf-8')\n",
    "chinese = lines.read().strip().split('\\n')\n",
    "lines = open('data/english.txt', encoding = 'utf-8')\n",
    "english = lines.read().strip().split('\\n')\n",
    "print(len(chinese))\n",
    "print(len(english))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两个特殊符号，分别对应句子头和句子尾\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "# 定义一个语言类，方便进行自动的建立、词频的统计等\n",
    "# 在这个对象中，最重要的是两个字典：word2index，index2word\n",
    "# 故名思议，第一个字典是将word映射到索引，第二个是将索引映射到word\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        # 在语言中添加一个新句子，句子是用空格隔开的一组单词\n",
    "        # 将单词切分出来，并分别进行处理\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        # 插入一个单词，如果单词已经在字典中，则更新字典中对应单词的频率\n",
    "        # 同时建立反向索引，可以从单词编号找到单词\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "# 将unicode编码转变为ascii编码\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# 把输入的英文字符串转成小写\n",
    "def normalizeEngString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "# 对输入的单词对做过滤，保证每句话的单词数不能超过MAX_LENGTH\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# 输入一个句子，输出一个单词对应的编码序列\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "# 和上面的函数功能类似，不同在于输出的序列等长＝MAX_LENGTH\n",
    "def indexFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    for i in range(MAX_LENGTH - len(indexes)):\n",
    "        indexes.append(EOS_token)\n",
    "    return(indexes)\n",
    "\n",
    "# 从一个词对到下标\n",
    "def indexFromPair(pair):\n",
    "    input_variable = indexFromSentence(input_lang, pair[0])\n",
    "    target_variable = indexFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "# 从一个列表到句子\n",
    "def SentenceFromList(lang, lst):\n",
    "    result = [lang.index2word[i] for i in lst if i != EOS_token]\n",
    "    if lang.name == 'Chinese':\n",
    "        result = ' '.join(result)\n",
    "    else:\n",
    "        result = ' '.join(result)\n",
    "    return(result)\n",
    "\n",
    "# 计算准确度的函数\n",
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行num_classes列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    pred = pred.view(-1, 1)\n",
    "    rights = pred.eq(labels.data).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有效句子对： 19919\n",
      "总单词数:\n",
      "English 13493\n",
      "Chinese 18671\n",
      "训练记录： 17928\n",
      "校验记录： 995\n",
      "测试记录： 996\n"
     ]
    }
   ],
   "source": [
    "# 处理数据形成训练数据\n",
    "# 设置句子的最大长度\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "#对英文做标准化处理\n",
    "pairs = [[normalizeEngString(eng), chi,] for chi, eng in zip(chinese, english)]\n",
    "\n",
    "# 对句子对做过滤，处理掉那些超过MAX_LENGTH长度的句子\n",
    "input_lang = Lang('English')\n",
    "output_lang = Lang('Chinese')\n",
    "pairs = [pair for pair in pairs if filterPair(pair)]\n",
    "print('有效句子对：', len(pairs))\n",
    "\n",
    "# 建立两个字典（中文的和英文的）\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "print(\"总单词数:\")\n",
    "print(input_lang.name, input_lang.n_words)\n",
    "print(output_lang.name, output_lang.n_words)\n",
    "\n",
    "\n",
    "# 形成训练集，首先，打乱所有句子的顺序\n",
    "random_idx = np.random.permutation(range(len(pairs)))\n",
    "pairs = [pairs[i] for i in random_idx]\n",
    "\n",
    "# 将语言转变为单词的编码构成的序列\n",
    "pairs = [indexFromPair(pair) for pair in pairs]\n",
    "    \n",
    "# 形成训练集、校验集和测试集\n",
    "valid_size = len(pairs) // 10\n",
    "if valid_size > 10000:\n",
    "    valid_size = 10000\n",
    "pairs = pairs[ : - valid_size]\n",
    "valid_pairs = pairs[-valid_size : -valid_size // 2]\n",
    "test_pairs = pairs[- valid_size // 2 :]\n",
    "\n",
    "# 利用PyTorch的dataset和dataloader对象，将数据加载到加载器里面，并且自动分批\n",
    "\n",
    "batch_size = 1024 #一撮包含30个数据记录，这个数字越大，系统在训练的时候，每一个周期处理的数据就越多，这样处理越快，但总的数据量会减少\n",
    "\n",
    "print('训练记录：', len(pairs))\n",
    "print('校验记录：', len(valid_pairs))\n",
    "print('测试记录：', len(test_pairs))\n",
    "\n",
    "# 形成训练对列表，用于喂给train_dataset\n",
    "pairs_X = [pair[0] for pair in pairs]\n",
    "pairs_Y = [pair[1] for pair in pairs]\n",
    "valid_X = [pair[0] for pair in valid_pairs]\n",
    "valid_Y = [pair[1] for pair in valid_pairs]\n",
    "test_X = [pair[0] for pair in test_pairs]\n",
    "test_Y = [pair[1] for pair in test_pairs]\n",
    "\n",
    "\n",
    "# 形成训练集\n",
    "train_dataset = DataSet.TensorDataset(torch.LongTensor(pairs_X), torch.LongTensor(pairs_Y))\n",
    "# 形成数据加载器\n",
    "train_loader = DataSet.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "\n",
    "# 校验数据\n",
    "valid_dataset = DataSet.TensorDataset(torch.LongTensor(valid_X), torch.LongTensor(valid_Y))\n",
    "valid_loader = DataSet.DataLoader(valid_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "# 测试数据\n",
    "test_dataset = DataSet.TensorDataset(torch.LongTensor(test_X), torch.LongTensor(test_Y))\n",
    "test_loader = DataSet.DataLoader(test_dataset, batch_size = batch_size, shuffle = True, num_workers = 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、构建编码器及简单的解码器RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建编码器RNN\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # 第一层Embeddeing\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # 第二层GRU，注意GRU中可以定义很多层，主要靠num_layers控制\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True, \n",
    "                          num_layers = self.n_layers, bidirectional = True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #前馈过程\n",
    "        #input尺寸： batch_size, length_seq\n",
    "        embedded = self.embedding(input)\n",
    "        #embedded尺寸：batch_size, length_seq, hidden_size\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # output尺寸：batch_size, length_seq, hidden_size\n",
    "        # hidden尺寸：num_layers * directions, batch_size, hidden_size\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # 对隐含单元变量全部进行初始化\n",
    "        #num_layers * num_directions, batch, hidden_size\n",
    "        result = Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "# 解码器网络\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # GRU单元\n",
    "        # 设置batch_first为True的作用就是为了让GRU接受的张量可以和其它单元类似，第一个维度为batch_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True,\n",
    "                        num_layers = self.n_layers, bidirectional = True)\n",
    "        # 最后的全链接层\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input大小：batch_size, length_seq\n",
    "        output = self.embedding(input)\n",
    "        # embedded大小：batch_size, length_seq, hidden_size\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # output大小：batch_size, length_seq, hidden_size * directions\n",
    "        # hidden大小：n_layers * directions, batch_size, hidden_size\n",
    "        output = self.softmax(self.out(output[:, -1, :]))\n",
    "        # output大小：batch_size * output_size\n",
    "        # 从output中取时间步重新开始\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # 初始化隐含单元的状态，输入变量的尺寸：num_layers * directions, batch_size, hidden_size\n",
    "        result = Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(t):\n",
    "    now = time.time()\n",
    "    s = now - t\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进程：0% 训练损失：156.7983，校验损失：117.3300，词正确率：38.64%, at 0m 9s \n",
      "进程：1% 训练损失：104.7127，校验损失：99.7316，词正确率：40.19%, at 0m 18s \n",
      "进程：2% 训练损失：91.1028，校验损失：85.7994，词正确率：34.65%, at 0m 27s \n",
      "进程：3% 训练损失：78.3524，校验损失：78.3611，词正确率：37.07%, at 0m 35s \n",
      "进程：4% 训练损失：74.0956，校验损失：76.2644，词正确率：39.42%, at 0m 44s \n",
      "进程：5% 训练损失：74.1638，校验损失：79.6615，词正确率：40.65%, at 0m 53s \n",
      "进程：6% 训练损失：74.2794，校验损失：80.9193，词正确率：39.40%, at 1m 2s \n",
      "进程：7% 训练损失：78.4859，校验损失：88.4677，词正确率：33.68%, at 1m 10s \n",
      "进程：8% 训练损失：79.1147，校验损失：83.4899，词正确率：36.39%, at 1m 19s \n",
      "进程：9% 训练损失：79.6772，校验损失：83.1703，词正确率：37.09%, at 1m 28s \n",
      "进程：10% 训练损失：77.8872，校验损失：80.7215，词正确率：41.53%, at 1m 37s \n",
      "进程：11% 训练损失：74.8109，校验损失：80.6421，词正确率：44.72%, at 1m 45s \n",
      "进程：12% 训练损失：71.5768，校验损失：75.8461，词正确率：43.93%, at 1m 54s \n",
      "进程：13% 训练损失：70.6515，校验损失：70.5725，词正确率：44.95%, at 2m 3s \n",
      "进程：14% 训练损失：66.9751，校验损失：69.0901，词正确率：45.39%, at 2m 12s \n",
      "进程：15% 训练损失：64.9716，校验损失：65.8245，词正确率：46.83%, at 2m 21s \n",
      "进程：16% 训练损失：63.6059，校验损失：65.5168，词正确率：47.44%, at 2m 29s \n",
      "进程：17% 训练损失：61.2257，校验损失：62.3979，词正确率：47.18%, at 2m 38s \n",
      "进程：18% 训练损失：58.2316，校验损失：60.6512，词正确率：48.23%, at 2m 47s \n",
      "进程：19% 训练损失：58.1872，校验损失：58.8554，词正确率：48.70%, at 2m 56s \n",
      "进程：20% 训练损失：54.8383，校验损失：58.2504，词正确率：49.08%, at 3m 5s \n",
      "进程：21% 训练损失：54.0318，校验损失：57.0656，词正确率：48.87%, at 3m 13s \n",
      "进程：22% 训练损失：54.7363，校验损失：55.3185，词正确率：50.08%, at 3m 22s \n",
      "进程：23% 训练损失：52.1495，校验损失：53.2951，词正确率：50.29%, at 3m 31s \n",
      "进程：24% 训练损失：49.5363，校验损失：52.9652，词正确率：50.31%, at 3m 40s \n",
      "进程：25% 训练损失：47.6957，校验损失：52.5595，词正确率：50.85%, at 3m 49s \n",
      "进程：26% 训练损失：46.4744，校验损失：52.6940，词正确率：51.61%, at 3m 57s \n",
      "进程：27% 训练损失：49.6963，校验损失：48.6022，词正确率：51.62%, at 4m 6s \n",
      "进程：28% 训练损失：44.3907，校验损失：48.7927，词正确率：50.82%, at 4m 15s \n",
      "进程：28% 训练损失：42.9088，校验损失：47.5558，词正确率：52.89%, at 4m 24s \n",
      "进程：30% 训练损失：42.4139，校验损失：46.9688，词正确率：52.66%, at 4m 33s \n",
      "进程：31% 训练损失：39.7659，校验损失：45.7803，词正确率：53.40%, at 4m 41s \n",
      "进程：32% 训练损失：40.4404，校验损失：44.2249，词正确率：54.77%, at 4m 50s \n",
      "进程：33% 训练损失：40.8101，校验损失：42.0598，词正确率：55.29%, at 4m 59s \n",
      "进程：34% 训练损失：37.5490，校验损失：41.0146，词正确率：55.17%, at 5m 8s \n",
      "进程：35% 训练损失：35.9237，校验损失：41.4586，词正确率：55.21%, at 5m 17s \n",
      "进程：36% 训练损失：37.1370，校验损失：40.5661，词正确率：56.09%, at 5m 26s \n",
      "进程：37% 训练损失：37.1686，校验损失：39.0491，词正确率：56.32%, at 5m 35s \n",
      "进程：38% 训练损失：31.8132，校验损失：39.7265，词正确率：56.77%, at 5m 43s \n",
      "进程：39% 训练损失：32.8413，校验损失：38.4276，词正确率：57.66%, at 5m 52s \n",
      "进程：40% 训练损失：32.5364，校验损失：36.8127，词正确率：57.92%, at 6m 1s \n",
      "进程：41% 训练损失：29.8030，校验损失：35.7387，词正确率：59.01%, at 6m 10s \n",
      "进程：42% 训练损失：31.1145，校验损失：35.2176，词正确率：58.70%, at 6m 18s \n",
      "进程：43% 训练损失：31.2038，校验损失：35.8140，词正确率：58.42%, at 6m 27s \n",
      "进程：44% 训练损失：31.0930，校验损失：38.4274，词正确率：55.20%, at 6m 36s \n",
      "进程：45% 训练损失：30.8709，校验损失：34.3122，词正确率：60.14%, at 6m 45s \n",
      "进程：46% 训练损失：30.5635，校验损失：32.5583，词正确率：60.40%, at 6m 54s \n",
      "进程：47% 训练损失：29.3258，校验损失：31.7764，词正确率：61.29%, at 7m 3s \n",
      "进程：48% 训练损失：26.4126，校验损失：31.7179，词正确率：62.21%, at 7m 11s \n",
      "进程：49% 训练损失：27.8623，校验损失：30.9036，词正确率：62.81%, at 7m 20s \n",
      "进程：50% 训练损失：23.8294，校验损失：31.0018，词正确率：62.67%, at 7m 29s \n",
      "进程：51% 训练损失：24.8044，校验损失：31.5404，词正确率：62.73%, at 7m 38s \n",
      "进程：52% 训练损失：24.3910，校验损失：28.7134，词正确率：64.98%, at 7m 47s \n",
      "进程：53% 训练损失：23.0462，校验损失：28.2692，词正确率：65.77%, at 7m 56s \n",
      "进程：54% 训练损失：25.3161，校验损失：28.1140，词正确率：65.08%, at 8m 4s \n",
      "进程：55% 训练损失：23.5439，校验损失：27.7844，词正确率：64.93%, at 8m 13s \n",
      "进程：56% 训练损失：22.7692，校验损失：27.8873，词正确率：64.99%, at 8m 22s \n",
      "进程：56% 训练损失：22.8330，校验损失：26.5262，词正确率：66.41%, at 8m 31s \n",
      "进程：57% 训练损失：19.9305，校验损失：25.4549，词正确率：68.22%, at 8m 39s \n",
      "进程：59% 训练损失：20.7003，校验损失：25.7268，词正确率：67.88%, at 8m 48s \n",
      "进程：60% 训练损失：19.6588，校验损失：24.9757，词正确率：68.61%, at 8m 57s \n",
      "进程：61% 训练损失：19.7380，校验损失：25.2204，词正确率：68.50%, at 9m 6s \n",
      "进程：62% 训练损失：23.3791，校验损失：24.3849，词正确率：68.85%, at 9m 15s \n",
      "进程：63% 训练损失：21.3912，校验损失：24.6703，词正确率：67.90%, at 9m 24s \n",
      "进程：64% 训练损失：19.8777，校验损失：24.2391，词正确率：69.04%, at 9m 33s \n",
      "进程：65% 训练损失：21.1756，校验损失：24.5056，词正确率：69.15%, at 9m 41s \n",
      "进程：66% 训练损失：20.4443，校验损失：24.0876，词正确率：69.57%, at 9m 50s \n",
      "进程：67% 训练损失：19.6674，校验损失：24.6206，词正确率：69.64%, at 9m 59s \n",
      "进程：68% 训练损失：18.4234，校验损失：24.8488，词正确率：69.70%, at 10m 8s \n",
      "进程：69% 训练损失：21.3969，校验损失：24.4575，词正确率：69.46%, at 10m 17s \n",
      "进程：70% 训练损失：17.5207，校验损失：23.5593，词正确率：70.84%, at 10m 26s \n",
      "进程：71% 训练损失：17.6637，校验损失：22.7064，词正确率：71.69%, at 10m 34s \n",
      "进程：72% 训练损失：16.5224，校验损失：22.4115，词正确率：72.11%, at 10m 43s \n",
      "进程：73% 训练损失：18.8685，校验损失：22.1659，词正确率：72.18%, at 10m 52s \n",
      "进程：74% 训练损失：17.4770，校验损失：22.1773，词正确率：72.83%, at 11m 1s \n",
      "进程：75% 训练损失：16.3051，校验损失：23.2726，词正确率：72.43%, at 11m 9s \n",
      "进程：76% 训练损失：15.8072，校验损失：21.3539，词正确率：73.72%, at 11m 18s \n",
      "进程：77% 训练损失：18.4719，校验损失：19.9890，词正确率：74.83%, at 11m 27s \n",
      "进程：78% 训练损失：15.3415，校验损失：20.1010，词正确率：74.89%, at 11m 36s \n",
      "进程：79% 训练损失：15.7734，校验损失：20.2223，词正确率：74.62%, at 11m 45s \n",
      "进程：80% 训练损失：13.8547，校验损失：21.4093，词正确率：74.98%, at 11m 54s \n",
      "进程：81% 训练损失：14.6992，校验损失：21.0157，词正确率：75.17%, at 12m 2s \n",
      "进程：82% 训练损失：13.8603，校验损失：19.9298，词正确率：76.27%, at 12m 11s \n",
      "进程：83% 训练损失：13.1441，校验损失：17.5902，词正确率：78.69%, at 12m 20s \n",
      "进程：84% 训练损失：13.5944，校验损失：17.3761，词正确率：79.07%, at 12m 28s \n",
      "进程：85% 训练损失：14.1336，校验损失：16.2317，词正确率：79.72%, at 12m 37s \n",
      "进程：86% 训练损失：13.0954，校验损失：15.8334，词正确率：79.70%, at 12m 46s \n",
      "进程：87% 训练损失：15.1284，校验损失：17.6294，词正确率：77.99%, at 12m 55s \n",
      "进程：88% 训练损失：12.3683，校验损失：17.0696，词正确率：79.09%, at 13m 4s \n",
      "进程：89% 训练损失：11.7905，校验损失：16.7238，词正确率：79.58%, at 13m 12s \n",
      "进程：90% 训练损失：13.9791，校验损失：15.4456，词正确率：80.68%, at 13m 21s \n",
      "进程：91% 训练损失：14.1100，校验损失：16.0410，词正确率：79.71%, at 13m 30s \n",
      "进程：92% 训练损失：13.7179，校验损失：16.9635，词正确率：78.63%, at 13m 39s \n",
      "进程：93% 训练损失：12.7214，校验损失：16.1369，词正确率：79.98%, at 13m 47s \n",
      "进程：94% 训练损失：14.4003，校验损失：16.9676，词正确率：79.09%, at 13m 56s \n",
      "进程：95% 训练损失：13.2816，校验损失：17.3678，词正确率：78.56%, at 14m 5s \n",
      "进程：96% 训练损失：12.7924，校验损失：16.4136，词正确率：80.15%, at 14m 14s \n",
      "进程：97% 训练损失：15.1489，校验损失：19.6818，词正确率：76.51%, at 14m 22s \n",
      "进程：98% 训练损失：15.5517，校验损失：19.2177，词正确率：76.94%, at 14m 32s \n",
      "进程：99% 训练损失：14.9521，校验损失：18.8363，词正确率：77.70%, at 14m 40s \n"
     ]
    }
   ],
   "source": [
    "# 开始训练过程\n",
    "# 定义网络结构\n",
    "start = time.time()\n",
    "\n",
    "hidden_size = 512\n",
    "max_length = MAX_LENGTH\n",
    "n_layers = 1\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers = n_layers)\n",
    "decoder = DecoderRNN(hidden_size, output_lang.n_words, n_layers = n_layers)\n",
    "\n",
    "if use_cuda:\n",
    "    # 如果本机有GPU可用，则将模型加载到GPU上\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "learning_rate = 0.01\n",
    "# 为两个网络分别定义优化器\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.NLLLoss()\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "plot_losses = []\n",
    "\n",
    "# 开始200轮的循环\n",
    "num_epoch = 100\n",
    "for epoch in range(num_epoch):\n",
    "    print_loss_total = 0\n",
    "    # 对训练数据循环\n",
    "    for data in train_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "        \n",
    "        # 初始化编码器状态\n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "        # 清空梯度\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        # 开始编码器的计算，对时间步的循环由系统自动完成\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "        \n",
    "        # 开始解码器的工作\n",
    "        # 输入给解码器的第一个字符\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        # 让解码器的隐藏层状态等于编码器的隐藏层状态\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 以teacher_forcing_ratio的比例用target中的翻译结果作为监督信息\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        base = torch.zeros(target_variable.size()[0])\n",
    "        if use_teacher_forcing:\n",
    "            # 教师监督: 将下一个时间步的监督信息输入给解码器\n",
    "            # 对时间步循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # 开始一步解码\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                # decoder_ouput大小：batch_size, output_size\n",
    "                # 计算损失函数\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "                # 将训练数据当做下一时间步的输入\n",
    "                decoder_input = target_variable[:, di].unsqueeze(1)  # Teacher forcing\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "                \n",
    "        else:\n",
    "            # 没有教师训练: 使用解码器自己的预测作为下一时间步的输入\n",
    "            # 开始对时间步进行循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # 进行一步解码\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "                \n",
    "                #从输出结果（概率的对数值）中选择出一个数值最大的单词作为输出放到了topi中\n",
    "                topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "                #topi 尺寸：batch_size, k\n",
    "                ni = topi[:, 0]\n",
    "\n",
    "                # 将输出结果ni包裹成Variable作为解码器的输入\n",
    "                decoder_input = Variable(ni.unsqueeze(1))\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "                #计算损失函数\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "        \n",
    "            \n",
    "        \n",
    "        # 开始反向传播\n",
    "        loss.backward()\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        # 开始梯度下降\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        # 累加总误差\n",
    "        print_loss_total += loss.data.numpy()[0]\n",
    "\n",
    "    # 计算训练时候的平均误差\n",
    "    print_loss_avg = print_loss_total / len(train_loader)\n",
    "        \n",
    "    # 开始跑校验数据集\n",
    "    valid_loss = 0\n",
    "    rights = []\n",
    "    # 对校验数据集循环\n",
    "    for data in valid_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "\n",
    "        loss = 0\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 没有教师监督: 使用解码器自己的预测作为下一时间步解码器的输入\n",
    "        for di in range(MAX_LENGTH):\n",
    "            # 一步解码器运算\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "            \n",
    "            # 选择输出最大的项作为解码器的预测答案\n",
    "            topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "            #topi 尺寸：batch_size, k\n",
    "            ni = topi[:, 0]\n",
    "            decoder_input = Variable(ni.unsqueeze(1))\n",
    "            # decoder_input大小：batch_size, length_seq\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            \n",
    "            # 计算预测的准确率，记录在right中，right为一个二元组，分别存储猜对的个数和总数\n",
    "            right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "            rights.append(right)\n",
    "            \n",
    "            # 计算损失函数\n",
    "            loss += criterion(decoder_output, target_variable[:, di])\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        # 累加校验时期的损失函数\n",
    "        valid_loss += loss.data.numpy()[0]\n",
    "    # 打印每一个Epoch的输出结果\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('进程：%d%% 训练损失：%.4f，校验损失：%.4f，词正确率：%.2f%%, at %s ' % (epoch * 1.0 / num_epoch * 100, \n",
    "                                                    print_loss_avg,\n",
    "                                                    valid_loss / len(valid_loader),\n",
    "                                                    100.0 * right_ratio,\n",
    "                                                    time_since(start)))\n",
    "    # 记录基本统计指标\n",
    "    plot_losses.append([print_loss_avg, valid_loss / len(valid_loader), right_ratio])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f943574fa20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94895e25f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将统计指标绘图\n",
    "a = [i[0] for i in plot_losses]\n",
    "b = [i[1] for i in plot_losses]\n",
    "c = [i[2] * 100 for i in plot_losses]\n",
    "plt.plot(a, label = 'Training Loss')\n",
    "plt.plot(b, label = 'Validation Loss')\n",
    "plt.plot(c, label = 'Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss & Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zhu bangzao said settling disputes through peaceful negotiations is the only correct available option for israel and palestine .\n",
      "机器翻译： 朱邦造 说 , 以 巴 之间 通过 和平谈判 解决 彼此 争端 是 唯一 可供 选择 的 正确 道路 .\n",
      "标准翻译： 朱邦造 说 , 以 巴 之间 通过 和平谈判 解决 彼此 争端 是 唯一 可供 选择 的 正确 道路 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "health permitting he said he would continue to stay here .\n",
      "机器翻译： 如果 身体 条件 的话 的话 , 身体 想 的话 , 一直 干 下去 .\n",
      "标准翻译： 如果 身体 条件 允许 的话 , 他 想 在这里 一直 干 下去 .\n",
      "词准确率： 60.0\n",
      "\n",
      "\n",
      "when forms are put in the first place contents must be subordinated to forms .\n",
      "机器翻译： 形式 形式 首位 , 要 反而 要 服从 形式 形式 .\n",
      "标准翻译： 形式 变成 首位 , 内容 反而 要 服从 形式 .\n",
      "词准确率： 80.0\n",
      "\n",
      "\n",
      "the fact is many countries have already spoken out on us human rights conditions .\n",
      "机器翻译： 事实上 , 许多 国家 已经 对 美国 的 人权 状况 说话 了 .\n",
      "标准翻译： 事实上 , 许多 国家 已经 对 美国 的 人权 状况 说话 了 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "the outline draft sketches the blueprint for construction in the first five years of the new century .\n",
      "机器翻译： ( 纲要 草案 ) 勾画出 了 新世纪 ) 新世纪 的 第一 年 .\n",
      "标准翻译： 纲要 ( 草案 ) 勾画出 了 新世纪 第一 五 年 的 建设 蓝图 .\n",
      "词准确率： 55.0\n",
      "\n",
      "\n",
      "his sudden death brought to light the succession question overnight .\n",
      "机器翻译： 他 的 去世 去世 使 国内 的 接班 问题 使 使 突然 在 继续 保持 .\n",
      "标准翻译： 他 的 突然 去世 , 使 国内 的 接班 问题 在 一 夜 之间 凸 显出来 .\n",
      "词准确率： 30.0\n",
      "\n",
      "\n",
      "the land issue has always been one of the most sensitive issues in rural areas .\n",
      "机器翻译： 土地 问题 , 历来 是 农村 最 敏感 的 问题 之一 .\n",
      "标准翻译： 土地 问题 , 历来 是 农村 最 敏感 的 问题 之一 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "the key lies in judging him by his deeds and observing what the taiwan authorities are doing .\n",
      "机器翻译： 关键 在 观其行 , 看看 看看 在 观其行 做 什 麽 .\n",
      "标准翻译： 关键 在 观其行 , 看看 台湾 当局 在 做 什 麽 .\n",
      "词准确率： 85.0\n",
      "\n",
      "\n",
      "guarding against and defusing international financial risks is the most urgent topic for safeguarding stable world economic development .\n",
      "机器翻译： 防范 和 化解 国际 金融 风险 , 是 维护 世界 经济 平稳 发展 最为 紧迫 的 最为 发展 .\n",
      "标准翻译： 防范 和 化解 国际 金融 风险 , 是 维护 世界 经济 平稳 发展 的 最为 紧迫 的 课题 .\n",
      "词准确率： 75.0\n",
      "\n",
      "\n",
      "cppcc committee member xuan ping said the institutional obstacles have to be removed by means of innovations .\n",
      "机器翻译： 宣平 委员 提出 , 体制 性 障碍 , 需要 来 来 清除 清除 .\n",
      "标准翻译： 宣平 委员 提出 , 体制 性 障碍 , 需要 用 创新 来 清除 .\n",
      "词准确率： 85.0\n",
      "\n",
      "\n",
      "what is his original intention ? .\n",
      "机器翻译： 一 , 他 的 愿 景 是 什 麽 ?\n",
      "标准翻译： 一 , 他 的 愿 景 是 什 麽 ?\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "the chinese side expressed high appreciation for the above stand of its thai counterpart .\n",
      "机器翻译： 中方 高度 赞赏 泰方 上述 立场 .\n",
      "标准翻译： 中方 高度 赞赏 泰方 上述 立场 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "leaders of the division felt at east and began to smile .\n",
      "机器翻译： 师 领导 心中 的 领导 石头 落 了 , , 紧锁 的 眉头 舒展 开 了 .\n",
      "标准翻译： 师 领导 心中 的 一块 石头 落 了 地 , 紧锁 的 眉头 舒展 开 了 .\n",
      "词准确率： 90.0\n",
      "\n",
      "\n",
      "he briefed the guests on china s domestic situation and its views on the present international situation .\n",
      "机器翻译： 他 还 介绍 了 中国 国内 的 形势 对 国内 形势 的 看法 的 看法 .\n",
      "标准翻译： 他 还 介绍 了 中国 国内 的 形势 和 对 当前 国际 形势 的 看法 .\n",
      "词准确率： 75.0\n",
      "\n",
      "\n",
      "question lastly what are your expectations about china us relations in the new century .\n",
      "机器翻译： 问 : 最后 您 最后 最后 对 新世纪 关系 有 有 最后 最后 .\n",
      "标准翻译： 问 : 最后 , 您 对 新世纪 的 中美 关系 有 何 期望 ?\n",
      "词准确率： 50.0\n",
      "\n",
      "\n",
      "he also took time to read the selected works of kim chong il in the evenings .\n",
      "机器翻译： 他 还 抽出 时间 挑灯 夜 读 《 金正日 文集 》 .\n",
      "标准翻译： 他 还 抽出 时间 挑灯 夜 读 《 金正日 文集 》 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "a chinese foreign ministry spokesperson made remarks on the incident .\n",
      "机器翻译： 中国 外交部 发言人 也就 上述 事件 发表 谈话 .\n",
      "标准翻译： 中国 外交部 发言人 也就 上述 事件 发表 谈话 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "in reality such happenings were not unique to the wto information center .\n",
      "机器翻译： 其实 , 类似 的 遭遇 并不是 WTO 信息 查询 有 所 独 的 .\n",
      "标准翻译： 其实 , 类似 的 遭遇 并不是 WTO 信息 查询 中心 所 独 有 .\n",
      "词准确率： 90.0\n",
      "\n",
      "\n",
      "we must therefore strive to enhance the market competitiveness of our livestock industry .\n",
      "机器翻译： 为此 , 必须 提 畜牧业 我国 畜牧业 我国 我国 市场 竞争 能力 .\n",
      "标准翻译： 为此 , 必须 努力 提 我国 畜牧业 的 市场 竞争 能力 .\n",
      "词准确率： 60.0\n",
      "\n",
      "\n",
      "with the exception of grain output which decreased all major targets for agricultural development were basically achieved .\n",
      "机器翻译： 随着 粮食 减产 外 , 基本 实现 了 农业 发展 的 预期 目标 .\n",
      "标准翻译： 除 粮食 减产 外 , 基本 实现 了 农业 发展 的 预期 目标 .\n",
      "词准确率： 95.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上测试模型运行的效果\n",
    "\n",
    "# 首先，在测试集中随机选择20个句子作为测试\n",
    "indices = np.random.choice(range(len(test_X)), 20)\n",
    "\n",
    "# 对每个句子进行循环\n",
    "for ind in indices:\n",
    "    data = [test_X[ind]]\n",
    "    target = [test_Y[ind]]\n",
    "    # 把源语言的句子打印出来\n",
    "    print(SentenceFromList(input_lang, data[0]))\n",
    "    input_variable = Variable(torch.LongTensor(data)).cuda() if use_cuda else Variable(torch.LongTensor(data))\n",
    "    # input_variable的大小：batch_size, length_seq\n",
    "    target_variable = Variable(torch.LongTensor(target)).cuda() if use_cuda else Variable(torch.LongTensor(target))\n",
    "    # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "    # 初始化编码器\n",
    "    encoder_hidden = encoder.initHidden(input_variable.size()[0])\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    # 编码器开始编码，结果存储到了encoder_hidden中\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "    # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    # 将SOS作为解码器的第一个输入\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "    # decoder_input大小：batch_size, length_seq\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    # 将编码器的隐含层单元数值拷贝给解码器的隐含层单元\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    # 没有教师指导下的预测: 使用解码器自己的预测作为解码器下一时刻的输入\n",
    "    output_sentence = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    rights = []\n",
    "    # 按照输出字符进行时间步循环\n",
    "    for di in range(MAX_LENGTH):\n",
    "        # 解码器一个时间步的计算\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "        \n",
    "        # 解码器的输出\n",
    "        topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "        #topi 尺寸：batch_size, k\n",
    "        ni = topi[:, 0]\n",
    "        decoder_input = Variable(ni.unsqueeze(1))\n",
    "        ni = ni.cpu().numpy()[0]\n",
    "        \n",
    "        # 将本时间步输出的单词编码加到output_sentence里面\n",
    "        output_sentence.append(ni)\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        \n",
    "        # 计算输出字符的准确度\n",
    "        right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "        rights.append(right)\n",
    "    # 解析出编码器给出的翻译结果\n",
    "    sentence = SentenceFromList(output_lang, output_sentence)\n",
    "    # 解析出标准答案\n",
    "    standard = SentenceFromList(output_lang, target[0])\n",
    "    \n",
    "    # 将句子打印出来\n",
    "    print('机器翻译：', sentence)\n",
    "    print('标准翻译：', standard)\n",
    "    # 输出本句话的准确率\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('词准确率：', 100.0 * right_ratio)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有效句子对： 19919\n",
      "总单词数:\n",
      "English 13493\n",
      "Chinese 18671\n",
      "训练记录： 17928\n",
      "校验记录： 995\n",
      "测试记录： 996\n"
     ]
    }
   ],
   "source": [
    "# 重新处理数据形成训练数据、校验数据与测试数据，主要是MAX_Length更大了\n",
    "# 设置句子的最大长度\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "#对英文做标准化处理\n",
    "pairs = [[normalizeEngString(eng), chi] for chi, eng in zip(chinese, english)]\n",
    "\n",
    "# 对句子对做过滤，处理掉那些超过MAX_LENGTH长度的句子\n",
    "input_lang = Lang('English')\n",
    "output_lang = Lang('Chinese')\n",
    "pairs = [pair for pair in pairs if filterPair(pair)]\n",
    "print('有效句子对：', len(pairs))\n",
    "\n",
    "# 建立两个字典（中文的和英文的）\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "print(\"总单词数:\")\n",
    "print(input_lang.name, input_lang.n_words)\n",
    "print(output_lang.name, output_lang.n_words)\n",
    "\n",
    "\n",
    "# 形成训练集，首先，打乱所有句子的顺序\n",
    "random_idx = np.random.permutation(range(len(pairs)))\n",
    "pairs = [pairs[i] for i in random_idx]\n",
    "\n",
    "# 将语言转变为单词的编码构成的序列\n",
    "pairs = [indexFromPair(pair) for pair in pairs]\n",
    "    \n",
    "# 形成训练集、校验集和测试集\n",
    "valid_size = len(pairs) // 10\n",
    "if valid_size > 10000:\n",
    "    valid_size = 10000\n",
    "pairs = pairs[ : - valid_size]\n",
    "valid_pairs = pairs[-valid_size : -valid_size // 2]\n",
    "test_pairs = pairs[- valid_size // 2 :]\n",
    "\n",
    "# 利用PyTorch的dataset和dataloader对象，将数据加载到加载器里面，并且自动分批\n",
    "\n",
    "batch_size = 30 #一撮包含30个数据记录，这个数字越大，系统在训练的时候，每一个周期处理的数据就越多，这样处理越快，但总的数据量会减少\n",
    "\n",
    "print('训练记录：', len(pairs))\n",
    "print('校验记录：', len(valid_pairs))\n",
    "print('测试记录：', len(test_pairs))\n",
    "\n",
    "# 形成训练对列表，用于喂给train_dataset\n",
    "pairs_X = [pair[0] for pair in pairs]\n",
    "pairs_Y = [pair[1] for pair in pairs]\n",
    "valid_X = [pair[0] for pair in valid_pairs]\n",
    "valid_Y = [pair[1] for pair in valid_pairs]\n",
    "test_X = [pair[0] for pair in test_pairs]\n",
    "test_Y = [pair[1] for pair in test_pairs]\n",
    "\n",
    "\n",
    "# 形成训练集\n",
    "train_dataset = DataSet.TensorDataset(torch.LongTensor(pairs_X), torch.LongTensor(pairs_Y))\n",
    "# 形成数据加载器\n",
    "train_loader = DataSet.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "\n",
    "# 校验数据\n",
    "valid_dataset = DataSet.TensorDataset(torch.LongTensor(valid_X), torch.LongTensor(valid_Y))\n",
    "valid_loader = DataSet.DataLoader(valid_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "# 测试数据\n",
    "test_dataset = DataSet.TensorDataset(torch.LongTensor(test_X), torch.LongTensor(test_Y))\n",
    "test_loader = DataSet.DataLoader(test_dataset, batch_size = batch_size, shuffle = True, num_workers = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义基于注意力的解码器RNN\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # 词嵌入层\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        # 注意力网络（一个前馈神经网络）\n",
    "        self.attn = nn.Linear(self.hidden_size * (2 * n_layers + 1), self.max_length)\n",
    "    \n",
    "        # 注意力机制作用完后的结果映射到后面的层\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
    "        \n",
    "        # dropout操作层\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        # 定义一个双向GRU，并设置batch_first为True以方便操作\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, bidirectional = True,\n",
    "                         num_layers = self.n_layers, batch_first = True)\n",
    "        self.out = nn.Linear(self.hidden_size * 2, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # 解码器的一步操作\n",
    "        # input大小：batch_size, length_seq\n",
    "        embedded = self.embedding(input)\n",
    "        # embedded大小：batch_size, length_seq, hidden_size\n",
    "        embedded = embedded[:, 0, :]\n",
    "        # embedded大小：batch_size, hidden_size\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # 将hidden张量数据转化成batch_size排在第0维的形状\n",
    "        # hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "        temp_for_transpose = torch.transpose(hidden, 0, 1).contiguous()\n",
    "        temp_for_transpose = temp_for_transpose.view(temp_for_transpose.size()[0], -1)\n",
    "        hidden_attn = temp_for_transpose\n",
    "        \n",
    "        # 注意力层的输入\n",
    "        # hidden_attn大小：batch_size, direction*n_layers*hidden_size\n",
    "        input_to_attention = torch.cat((embedded, hidden_attn), 1)\n",
    "        # input_to_attention大小：batch_size, hidden_size * (1 + direction * n_layers)\n",
    "        \n",
    "        # 注意力层输出的权重\n",
    "        attn_weights = F.softmax(self.attn(input_to_attention))\n",
    "        # attn_weights大小：batch_size, max_length\n",
    "        \n",
    "        # 当输入数据不标准的时候，对weights截取必要的一段\n",
    "        attn_weights = attn_weights[:, : encoder_outputs.size()[1]]\n",
    "        # attn_weights大小：batch_size, length_seq_of_encoder\n",
    "        attn_weights = attn_weights.unsqueeze(1)\n",
    "        # attn_weights大小：batch_size, 1, length_seq 中间的1是为了bmm乘法用的\n",
    "        \n",
    "        # 将attention的weights矩阵乘encoder_outputs以计算注意力完的结果\n",
    "        # encoder_outputs大小：batch_size, seq_length, hidden_size*direction\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_outputs) \n",
    "        # attn_applied大小：batch_size, 1, hidden_size*direction\n",
    "        # bmm: 两个矩阵相乘。忽略第一个batch纬度，缩并时间维度\n",
    "        \n",
    "        # 将输入的词向量与注意力机制作用后的结果拼接成一个大的输入向量\n",
    "        output = torch.cat((embedded, attn_applied[:,0,:]), 1)\n",
    "        # output大小：batch_size, hidden_size * (direction + 1)\n",
    "        \n",
    "        # 将大输入向量映射为GRU的隐含层\n",
    "        output = self.attn_combine(output).unsqueeze(1)\n",
    "        # output大小：batch_size, length_seq, hidden_size\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # output的结果再dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # 开始解码器GRU的运算\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        \n",
    "        # output大小：batch_size, length_seq, hidden_size * directions\n",
    "        # hidden大小：n_layers * directions, batch_size, hidden_size\n",
    "        \n",
    "        #取出GRU运算最后一步的结果喂给最后一层全链接层\n",
    "        output = self.out(output[:, -1, :])\n",
    "        # output大小：batch_size * output_size\n",
    "        \n",
    "        # 取logsoftmax，计算输出结果\n",
    "        output = F.log_softmax(output)\n",
    "        # output大小：batch_size * output_size\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # 初始化解码器隐单元，尺寸为n_layers * directions, batch_size, hidden_size\n",
    "        result = Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进程：0% 训练损失：91.2160，校验损失：87.4878，词正确率：42.58% at 1m 44s\n",
      "进程：1% 训练损失：82.8542，校验损失：83.6274，词正确率：43.01% at 3m 28s\n",
      "进程：2% 训练损失：78.7738，校验损失：79.9690，词正确率：43.72% at 5m 10s\n",
      "进程：3% 训练损失：75.4363，校验损失：77.1736，词正确率：43.93% at 6m 54s\n",
      "进程：4% 训练损失：72.5687，校验损失：73.8263，词正确率：44.49% at 8m 37s\n",
      "进程：5% 训练损失：69.7428，校验损失：71.4972，词正确率：44.84% at 10m 20s\n",
      "进程：6% 训练损失：66.9764，校验损失：68.6419，词正确率：45.38% at 11m 57s\n",
      "进程：7% 训练损失：64.6855，校验损失：65.8239，词正确率：45.88% at 13m 39s\n",
      "进程：8% 训练损失：62.3569，校验损失：63.8708，词正确率：46.55% at 15m 22s\n",
      "进程：9% 训练损失：59.7454，校验损失：61.0601，词正确率：46.93% at 17m 5s\n",
      "进程：10% 训练损失：57.6412，校验损失：58.5582，词正确率：47.54% at 18m 49s\n",
      "进程：11% 训练损失：55.4660，校验损失：55.8455，词正确率：48.48% at 20m 33s\n",
      "进程：12% 训练损失：53.4045，校验损失：53.6359，词正确率：49.54% at 22m 16s\n",
      "进程：13% 训练损失：51.2436，校验损失：52.2306，词正确率：50.16% at 23m 59s\n",
      "进程：14% 训练损失：49.3243，校验损失：50.1005，词正确率：51.08% at 25m 43s\n",
      "进程：15% 训练损失：47.7357，校验损失：48.7334，词正确率：52.69% at 27m 28s\n",
      "进程：16% 训练损失：45.9257，校验损失：46.9938，词正确率：52.87% at 29m 11s\n",
      "进程：17% 训练损失：44.1392，校验损失：44.6821，词正确率：53.66% at 30m 55s\n",
      "进程：18% 训练损失：42.7618，校验损失：43.6150，词正确率：54.90% at 32m 39s\n",
      "进程：19% 训练损失：41.2931，校验损失：41.9610，词正确率：55.63% at 34m 23s\n",
      "进程：20% 训练损失：39.8401，校验损失：41.0153，词正确率：56.20% at 36m 3s\n",
      "进程：21% 训练损失：38.7667，校验损失：39.6308，词正确率：57.29% at 37m 47s\n",
      "进程：22% 训练损失：37.6348，校验损失：38.7834，词正确率：57.32% at 39m 18s\n",
      "进程：23% 训练损失：36.2674，校验损失：37.0676，词正确率：58.56% at 41m 2s\n",
      "进程：24% 训练损失：35.0543，校验损失：35.6972，词正确率：59.50% at 42m 45s\n",
      "进程：25% 训练损失：34.1252，校验损失：34.2551，词正确率：60.36% at 44m 29s\n",
      "进程：26% 训练损失：32.9009，校验损失：33.5755，词正确率：60.87% at 45m 56s\n",
      "进程：27% 训练损失：31.8378，校验损失：32.8707，词正确率：61.51% at 47m 40s\n",
      "进程：28% 训练损失：30.9557，校验损失：32.3219，词正确率：62.18% at 49m 24s\n",
      "进程：28% 训练损失：29.8132，校验损失：31.0269，词正确率：62.85% at 51m 8s\n",
      "进程：30% 训练损失：29.1125，校验损失：29.8716，词正确率：64.10% at 52m 52s\n",
      "进程：31% 训练损失：28.1398，校验损失：28.4310，词正确率：64.60% at 54m 36s\n",
      "进程：32% 训练损失：27.3858，校验损失：27.6849，词正确率：65.63% at 56m 21s\n",
      "进程：33% 训练损失：26.4815，校验损失：27.2579，词正确率：65.51% at 57m 46s\n",
      "进程：34% 训练损失：25.7501，校验损失：26.0376，词正确率：66.85% at 59m 27s\n",
      "进程：35% 训练损失：24.7909，校验损失：25.8406，词正确率：67.45% at 61m 12s\n",
      "进程：36% 训练损失：23.9816，校验损失：24.4887，词正确率：68.73% at 62m 33s\n",
      "进程：37% 训练损失：23.3795，校验损失：23.6855，词正确率：69.45% at 64m 15s\n",
      "进程：38% 训练损失：22.4987，校验损失：23.2408，词正确率：70.20% at 65m 59s\n",
      "进程：39% 训练损失：22.0401，校验损失：22.4422，词正确率：71.19% at 67m 11s\n",
      "进程：40% 训练损失：21.2392，校验损失：21.8173，词正确率：71.52% at 68m 55s\n",
      "进程：41% 训练损失：20.7694，校验损失：20.8767，词正确率：72.52% at 70m 40s\n",
      "进程：42% 训练损失：19.8981，校验损失：19.5004，词正确率：74.13% at 72m 24s\n",
      "进程：43% 训练损失：19.0766，校验损失：19.1936，词正确率：74.83% at 74m 9s\n",
      "进程：44% 训练损失：18.8475，校验损失：19.4145，词正确率：74.47% at 75m 51s\n",
      "进程：45% 训练损失：18.1919，校验损失：17.7742，词正确率：76.21% at 77m 35s\n",
      "进程：46% 训练损失：17.4275，校验损失：17.3012，词正确率：76.66% at 79m 18s\n",
      "进程：47% 训练损失：16.8215，校验损失：16.6049，词正确率：77.67% at 81m 3s\n",
      "进程：48% 训练损失：16.3223，校验损失：16.2325，词正确率：77.95% at 82m 15s\n",
      "进程：49% 训练损失：16.1216，校验损失：15.6533，词正确率：78.98% at 84m 0s\n",
      "进程：50% 训练损失：15.2938，校验损失：15.0027，词正确率：80.08% at 85m 45s\n",
      "进程：51% 训练损失：14.8443，校验损失：14.3015，词正确率：80.77% at 87m 27s\n",
      "进程：52% 训练损失：14.3193，校验损失：13.7597，词正确率：81.55% at 89m 10s\n",
      "进程：53% 训练损失：13.9206，校验损失：13.1357，词正确率：81.77% at 90m 54s\n",
      "进程：54% 训练损失：13.6082，校验损失：12.8437，词正确率：82.39% at 92m 38s\n",
      "进程：55% 训练损失：12.8827，校验损失：11.8453，词正确率：84.41% at 94m 21s\n",
      "进程：56% 训练损失：12.3866，校验损失：11.5733，词正确率：84.62% at 96m 4s\n",
      "进程：56% 训练损失：12.0160，校验损失：10.8379，词正确率：86.18% at 97m 47s\n",
      "进程：57% 训练损失：11.7452，校验损失：10.9266，词正确率：85.67% at 99m 27s\n",
      "进程：59% 训练损失：11.2450，校验损失：10.1305，词正确率：87.07% at 101m 11s\n",
      "进程：60% 训练损失：11.0037，校验损失：9.8815，词正确率：87.17% at 102m 55s\n",
      "进程：61% 训练损失：10.7378，校验损失：9.3444，词正确率：88.12% at 104m 27s\n",
      "进程：62% 训练损失：10.3868，校验损失：9.2663，词正确率：87.33% at 106m 9s\n",
      "进程：63% 训练损失：9.9614，校验损失：8.9458，词正确率：88.34% at 107m 52s\n",
      "进程：64% 训练损失：9.5132，校验损失：7.9960，词正确率：90.32% at 109m 37s\n",
      "进程：65% 训练损失：9.1136，校验损失：7.8399，词正确率：90.39% at 111m 20s\n",
      "进程：66% 训练损失：8.8988，校验损失：7.4138，词正确率：90.94% at 113m 4s\n",
      "进程：67% 训练损失：8.6359，校验损失：7.3077，词正确率：91.26% at 114m 48s\n",
      "进程：68% 训练损失：8.2132，校验损失：6.9572，词正确率：91.83% at 116m 33s\n",
      "进程：69% 训练损失：8.0061，校验损失：6.5881，词正确率：92.23% at 118m 17s\n",
      "进程：70% 训练损失：7.7152，校验损失：6.4818，词正确率：92.20% at 120m 1s\n",
      "进程：71% 训练损失：7.6383，校验损失：6.2964，词正确率：92.39% at 121m 44s\n",
      "进程：72% 训练损失：7.3936，校验损失：6.5651，词正确率：92.53% at 123m 29s\n",
      "进程：73% 训练损失：7.0372，校验损失：5.7772，词正确率：93.17% at 124m 51s\n",
      "进程：74% 训练损失：6.8608，校验损失：5.4115，词正确率：94.12% at 126m 37s\n",
      "进程：75% 训练损失：6.7112，校验损失：5.1561，词正确率：94.14% at 128m 21s\n",
      "进程：76% 训练损失：6.4380，校验损失：4.9474，词正确率：94.43% at 130m 5s\n",
      "进程：77% 训练损失：6.2607，校验损失：4.7622，词正确率：94.70% at 131m 50s\n",
      "进程：78% 训练损失：6.0115，校验损失：4.4409，词正确率：95.31% at 133m 33s\n",
      "进程：79% 训练损失：5.9678，校验损失：4.4411，词正确率：95.32% at 134m 46s\n",
      "进程：80% 训练损失：5.6760，校验损失：4.2564，词正确率：95.42% at 135m 59s\n",
      "进程：81% 训练损失：5.4912，校验损失：3.9379，词正确率：95.81% at 137m 42s\n",
      "进程：82% 训练损失：5.4182，校验损失：4.4708，词正确率：95.42% at 139m 25s\n",
      "进程：83% 训练损失：5.2754，校验损失：3.6469，词正确率：96.52% at 141m 9s\n",
      "进程：84% 训练损失：4.9999，校验损失：3.7292，词正确率：96.13% at 142m 22s\n",
      "进程：85% 训练损失：5.0408，校验损失：3.3878，词正确率：96.61% at 144m 3s\n",
      "进程：86% 训练损失：4.7858，校验损失：3.4824，词正确率：96.50% at 145m 47s\n",
      "进程：87% 训练损失：4.6729，校验损失：3.4485，词正确率：96.41% at 147m 17s\n",
      "进程：88% 训练损失：4.5430，校验损失：2.9831，词正确率：97.23% at 149m 2s\n",
      "进程：89% 训练损失：4.4099，校验损失：2.9237，词正确率：97.29% at 150m 47s\n",
      "进程：90% 训练损失：4.2789，校验损失：2.8804，词正确率：97.41% at 152m 3s\n",
      "进程：91% 训练损失：4.2149，校验损失：2.8697，词正确率：97.09% at 153m 45s\n",
      "进程：92% 训练损失：4.0580，校验损失：2.9379，词正确率：97.37% at 155m 28s\n",
      "进程：93% 训练损失：3.9437，校验损失：2.5515，词正确率：97.62% at 157m 12s\n",
      "进程：94% 训练损失：3.7836，校验损失：2.6132，词正确率：97.29% at 158m 57s\n",
      "进程：95% 训练损失：3.7756，校验损失：2.4411，词正确率：97.61% at 160m 39s\n",
      "进程：96% 训练损失：3.5984，校验损失：2.2379，词正确率：97.90% at 161m 51s\n",
      "进程：97% 训练损失：3.5153，校验损失：2.2382，词正确率：98.05% at 163m 4s\n",
      "进程：98% 训练损失：3.5164，校验损失：2.1086，词正确率：98.14% at 164m 48s\n",
      "进程：99% 训练损失：3.3549，校验损失：2.1691，词正确率：98.18% at 166m 33s\n"
     ]
    }
   ],
   "source": [
    "# 开始带有注意力机制的RNN训练\n",
    "\n",
    "#定义网络架构\n",
    "start = time.time()\n",
    "\n",
    "hidden_size = 512\n",
    "max_length = MAX_LENGTH\n",
    "n_layers = 1\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers = n_layers)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.5,\n",
    "                         max_length = max_length, n_layers = n_layers)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "print_loss_total = 0  # Reset every print_every\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "#criterion = Batch_NLLLoss\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "# 开始训练周期循环\n",
    "plot_losses = []\n",
    "for epoch in range(num_epoch):\n",
    "    # 将解码器置于训练状态，让dropout工作\n",
    "    decoder.train()\n",
    "    print_loss_total = 0\n",
    "    # 对训练数据进行循环\n",
    "    for data in train_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "        \n",
    "        #清空梯度\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        #编码器开始工作\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 解码器开始工作\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        # 将编码器的隐含层单元取值作为编码的结果传递给解码器\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 同时按照两种方式训练解码器：用教师监督的信息作为下一时刻的输入和不用监督的信息，用自己预测结果作为下一时刻的输入\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        if use_teacher_forcing:\n",
    "            # 用监督信息作为下一时刻解码器的输入\n",
    "            # 开始时间不得循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # 输入给解码器的信息包括输入的单词decoder_input, 解码器上一时刻的因曾单元状态，\n",
    "                # 编码器各个时间步的输出结果\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                #decoder_ouput大小：batch_size, output_size\n",
    "                #计算损失函数，得到下一时刻的解码器的输入\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "                decoder_input = target_variable[:, di].unsqueeze(1)  # Teacher forcing\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "        else:\n",
    "            # 没有教师监督，用解码器自己的预测作为下一时刻的输入\n",
    "\n",
    "            # 对时间步进行循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "                # 获取解码器的预测结果，并用它来作为下一时刻的输入\n",
    "                topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "                #topi 尺寸：batch_size, k\n",
    "                ni = topi[:, 0]\n",
    "\n",
    "                decoder_input = Variable(ni.unsqueeze(1))\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "                # 计算损失函数\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 反向传播开始\n",
    "        loss.backward()\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        # 开始梯度下降\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        print_loss_total += loss.data.numpy()[0]\n",
    "\n",
    "    print_loss_avg = print_loss_total / len(train_loader)\n",
    "        \n",
    "    valid_loss = 0\n",
    "    rights = []\n",
    "    # 将解码器的training设置为False，以便关闭dropout\n",
    "    decoder.eval()\n",
    "    \n",
    "    #对所有的校验数据做循环\n",
    "    for data in valid_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "\n",
    "        loss = 0\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 开始每一步的预测\n",
    "        for di in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "            topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "            #topi 尺寸：batch_size, k\n",
    "            ni = topi[:, 0]\n",
    "\n",
    "            decoder_input = Variable(ni.unsqueeze(1))\n",
    "            # decoder_input大小：batch_size, length_seq\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "            rights.append(right)\n",
    "            loss += criterion(decoder_output, target_variable[:, di])\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        valid_loss += loss.data.numpy()[0]\n",
    "    # 计算平均损失、准确率等指标并打印输出\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('进程：%d%% 训练损失：%.4f，校验损失：%.4f，词正确率：%.2f%% at %s' % (epoch * 1.0 / num_epoch * 100, \n",
    "                                                    print_loss_avg,\n",
    "                                                    valid_loss / len(valid_loader),\n",
    "                                                    100.0 * right_ratio,\n",
    "                                                    time_since(start)))\n",
    "    plot_losses.append([print_loss_avg, valid_loss / len(valid_loader), right_ratio])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type AttnDecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f94895de908>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhcCZaQskgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94359f72e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制统计指标曲线图\n",
    "torch.save(encoder, 'encoder-final.mdl')\n",
    "torch.save(decoder, 'decoder-final.mdl')\n",
    "a = [i[0] for i in plot_losses]\n",
    "b = [i[1] for i in plot_losses]\n",
    "c = [i[2] * 100 for i in plot_losses]\n",
    "plt.plot(a, label = 'Training Loss')\n",
    "plt.plot(b, label = 'Validation Loss')\n",
    "plt.plot(c, label = 'Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss & Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he hoped to see a more active economic and trade relationship between the two sides in the future .\n",
      "机器翻译： 希望 双方 经贸 关系 变得 更加 积极 .\n",
      "标准翻译： 希望 双方 经贸 关系 变得 更加 积极 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "it is necessary to pursue and crack down on them relentlessly in a bid to uproot them all .\n",
      "机器翻译： 五 是 加大 文化 市场 的 整治 力度 .\n",
      "标准翻译： 五 是 加大 文化 市场 的 整治 力度 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "this may well be another awakening for the developing countries .\n",
      "机器翻译： 这 不妨 看成是 发展中国家 的 又 一次 觉醒 .\n",
      "标准翻译： 这 不妨 看成是 发展中国家 的 又 一次 觉醒 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "we must take this as a warning and the alarm bell should sound for a long time . .\n",
      "机器翻译： 我们 必须 引以为戒 , 警钟 长鸣 .\n",
      "标准翻译： 我们 必须 引以为戒 , 警钟 长鸣 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "we shall face severe challenges agriculturally after our country accedes to the wto .\n",
      "机器翻译： 在 我国 加入 世贸 组织 之后 , 农业 将 面临 严峻 的 挑战 .\n",
      "标准翻译： 在 我国 加入 世贸 组织 之后 , 农业 将 面临 严峻 的 挑战 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "he thanked the vietnamese government for its long term adherence to the one china policy .\n",
      "机器翻译： 傅全有 对 越南 政府 长期以来 奉行 \" 一个 中国 \" 的 政策 表示 感谢 .\n",
      "标准翻译： 傅全有 对 越南 政府 长期以来 奉行 \" 一个 中国 \" 的 政策 表示 感谢 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "the korean government opened a session of its cabinet ministers specifically with reference to the japanese textbook issue .\n",
      "机器翻译： 韩国 政府 就 日本 教科书 一 案 专门 召开 了 内阁 全体 部长会议 .\n",
      "标准翻译： 韩国 政府 就 日本 教科书 一 案 专门 召开 了 内阁 全体 部长会议 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "china is a permanent member of the security council it is also a developing country .\n",
      "机器翻译： 中国 是 安理会 的 常任 理事国 , 也是 一个 发展中国家 .\n",
      "标准翻译： 中国 是 安理会 的 常任 理事国 , 也是 一个 发展中国家 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "at present qian qichen s remarks have almost proved the viewpoint of the conservative faction .\n",
      "机器翻译： 如今 钱其琛 这 番 谈话 几乎 验证 保守派 观点 .\n",
      "标准翻译： 如今 钱其琛 这 番 谈话 几乎 验证 保守派 观点 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "in some localities and units the pace of economic development is comparatively sluggish .\n",
      "机器翻译： 对 图 虚名 , 说 假话 的 干部 , 绝 不能 提拔 和 重用 .\n",
      "标准翻译： 对 图 虚名 , 说 假话 的 干部 , 绝 不能 提拔 和 重用 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "the educational resources of the military units should be used to cultivate human resources for the poor areas .\n",
      "机器翻译： 充分 利用 军队 的 教育 资源 , 为 贫困 地区 培养 所需 人才 .\n",
      "标准翻译： 充分 利用 军队 的 教育 资源 , 为 贫困 地区 培养 所需 人才 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "peasants described such reform measures as one tax clean and simple . \n",
      "机器翻译： 农民 形 像 地 把 这种 改革 的 做法 称作 \" 一道 税 , 一口 一口 \" .\n",
      "标准翻译： 农民 形 像 地 把 这种 改革 的 做法 称作 \" 一道 税 , 一口 清 \" .\n",
      "词准确率： 95.0\n",
      "\n",
      "\n",
      "four there is a serious structural contradiction .\n",
      "机器翻译： 四 是 结构性 矛盾 突出 .\n",
      "标准翻译： 四 是 结构性 矛盾 突出 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "it is hoped that annette lu will not make a wrong assessment in this regard .\n",
      "机器翻译： 希望 吕秀莲 不要 对 这 方面 有 错误 的 估计 .\n",
      "标准翻译： 希望 吕秀莲 不要 对 这 方面 有 错误 的 估计 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "how to save taiwan ?\n",
      "机器翻译： 如何 救 台湾 呢 ?\n",
      "标准翻译： 如何 救 台湾 呢 ?\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "to turkmenistan the agreement is better than any gift .\n",
      "机器翻译： 这 份 协议 的 签署 对 土库曼 斯坦 来说 , 比 任何 礼物 都 更 实惠 .\n",
      "标准翻译： 这 份 协议 的 签署 对 土库曼 斯坦 来说 , 比 任何 礼物 都 更 实惠 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "the three day seminar will end on december .\n",
      "机器翻译： 会议 将 从 6日 至 8日 举行 3 天 .\n",
      "标准翻译： 会议 将 从 6日 至 8日 举行 3 天 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "us companies will also have greater access to china s financial and service sectors .\n",
      "机器翻译： 美国 公司 将 更多 地 进入 中国 的 金融 和 服务 市场 .\n",
      "标准翻译： 美国 公司 将 更多 地 进入 中国 的 金融 和 服务 市场 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "with operational requirements taking the lead we will form a battle and support unity mechanism .\n",
      "机器翻译： 以 作战 需求 为 牵引 , 形成 \" 战 保 一体 \" 的 机制 .\n",
      "标准翻译： 以 作战 需求 为 牵引 , 形成 \" 战 保 一体 \" 的 机制 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n",
      "on march dprk foreign minister paek nam sun visited china .\n",
      "机器翻译： 3月18日 , 朝鲜 外务 相 白南舜 访华 .\n",
      "标准翻译： 3月18日 , 朝鲜 外务 相 白南舜 访华 .\n",
      "词准确率： 100.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从测试集中随机挑选20个句子来测试翻译的结果\n",
    "indices = np.random.choice(range(len(test_X)), 20)\n",
    "for ind in indices:\n",
    "    data = [test_X[ind]]\n",
    "    target = [test_Y[ind]]\n",
    "    print(SentenceFromList(input_lang, data[0]))\n",
    "    input_variable = Variable(torch.LongTensor(data)).cuda() if use_cuda else Variable(torch.LongTensor(data))\n",
    "    # input_variable的大小：batch_size, length_seq\n",
    "    target_variable = Variable(torch.LongTensor(target)).cuda() if use_cuda else Variable(torch.LongTensor(target))\n",
    "    # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "    encoder_hidden = encoder.initHidden(input_variable.size()[0])\n",
    "\n",
    "    loss = 0\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "    # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "    # decoder_input大小：batch_size, length_seq\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    # Without teacher forcing: use its own predictions as the next input\n",
    "    output_sentence = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    rights = []\n",
    "    for di in range(MAX_LENGTH):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "        topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        #topi 尺寸：batch_size, k\n",
    "        ni = topi[:, 0]\n",
    "        decoder_input = Variable(ni.unsqueeze(1))\n",
    "        ni = ni.cpu().numpy()[0]\n",
    "        output_sentence.append(ni)\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "        rights.append(right)\n",
    "    sentence = SentenceFromList(output_lang, output_sentence)\n",
    "    standard = SentenceFromList(output_lang, target[0])\n",
    "    print('机器翻译：', sentence)\n",
    "    print('标准翻译：', standard)\n",
    "    # 输出本句话的准确率\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('词准确率：', 100.0 * right_ratio)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "机器翻译： 如何 救 台湾 呢 ?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 通过几个特殊的句子翻译，考察注意力机制关注的情况\n",
    "# data = '人民币 汇率 继续 保持 稳定 .'\n",
    "# data = '五 是 干部 交流 工作 迈出 较大 步伐 .'\n",
    "# data = '谈到 经济 合作 问题 , 两 人 找到 了 一些 共同 语言 .'\n",
    "data = 'how to save taiwan ?'\n",
    "\n",
    "data = np.array([indexFromSentence(input_lang, data)])\n",
    "\n",
    "input_variable = Variable(torch.LongTensor(data)).cuda() if use_cuda else Variable(torch.LongTensor(data))\n",
    "# input_variable的大小：batch_size, length_seq\n",
    "target_variable = Variable(torch.LongTensor(target)).cuda() if use_cuda else Variable(torch.LongTensor(target))\n",
    "# target_variable的大小：batch_size, length_seq\n",
    "\n",
    "encoder_hidden = encoder.initHidden(input_variable.size()[0])\n",
    "\n",
    "loss = 0\n",
    "encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "# encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "# encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "# decoder_input大小：batch_size, length_seq\n",
    "decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "decoder_hidden = encoder_hidden\n",
    "# decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "output_sentence = []\n",
    "decoder_attentions = torch.zeros(max_length, max_length)\n",
    "for di in range(MAX_LENGTH):\n",
    "    decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "        decoder_input, decoder_hidden, encoder_outputs)\n",
    "    #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "    topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "    \n",
    "    # 在每一步，获取了注意力的权重向量，并将其存储到了decoder_attentions之中\n",
    "    decoder_attentions[di] = decoder_attention.data\n",
    "    #topi 尺寸：batch_size, k\n",
    "    ni = topi[:, 0]\n",
    "    decoder_input = Variable(ni.unsqueeze(1))\n",
    "    ni = ni.cpu().numpy()[0]\n",
    "    output_sentence.append(ni)\n",
    "    # decoder_input大小：batch_size, length_seq\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "    rights.append(right)\n",
    "sentence = SentenceFromList(output_lang, output_sentence)\n",
    "print()\n",
    "print('机器翻译：', sentence)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9435832780>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADElJREFUeJzt3U2MVfUZx/Hfcy8Mw8ugIHZEa7BV\nqsGmJWZiN8ZCbA11oy7a1HbBwgYXdV9W6qILN8ZVa4ItgaTRxi6INjW+hA2tNY1DYhVbjRRBIcio\nyJsDM8y9TxdcnhCGcZ5z386dO99PQubew8N/njP3zo9zzvzPf8zdBQCSVCm7AQC9g0AAEAgEAIFA\nABAIBACBQAAQSg0EM9tkZh+Y2X4z21pmL51gZgfN7F0ze9vMRsvup1Vmtt3Mxsxs3yXbVprZ62b2\nYePjijJ7bMUM+/eEmR1pvIZvm9l9ZfbYaaUFgplVJf1O0k8krZP0kJmtK6ufDtro7uvdfaTsRtpg\nh6RNl23bKmm3u6+VtLvxfK7aoen7J0lPN17D9e7+cpd76qoyjxDulLTf3Q+4+6SkP0u6v8R+MAt3\n3yPp+GWb75e0s/F4p6QHutpUG82wf/NKmYFwg6RPLnl+uLGtn7ik18xsr5ltKbuZDhl296ONx59K\nGi6zmQ551MzeaZxSzNlTogwuKnbWXe5+hy6cFv3azO4uu6FO8gvz4PttLvwzkm6WtF7SUUlPldtO\nZ5UZCEck3XjJ8282tvUNdz/S+DgmaZcunCb1m2NmtlqSGh/HSu6nrdz9mLvX3L0u6Vn152sYygyE\ntyStNbNvmdmApJ9LeqnEftrKzJaa2dDFx5LulbTv6//VnPSSpM2Nx5slvVhiL213MewaHlR/voZh\nQVmf2N2nzOxRSa9Kqkra7u7vldVPBwxL2mVm0oWv83Pu/kq5LbXGzJ6XtEHSKjM7LOlxSU9KesHM\nHpZ0SNLPyuuwNTPs3wYzW68Lp0IHJT1SWoNdYNz+DOAiLioCCAQCgEAgAAgEAoBAIAAIPREIfTyt\nt6/3TWL/+k1PBIKkfv6i9/O+SexfX+mVQADQA7o6MWnAFvmglk7bfl4TWqhFTY9rg8X+rZ+byI+9\ncGG69tzqgWnbamfOqLps2bTtg5/V0uN61dK1kqQzZ4vVJ1m1Om3bpJ/TgA1O2+71/P718u1Qrb43\ne8U5faVJn5j1jdTVqcuDWqof2D1tH7d60y2F6msf7E/XLhi+Pl3739/cOHtRw63bTqZrp1YsTtdK\nUuXv7+SLC3zjVq/K3/lbP306XetTU+laNOdfvjtV19IpQ78vgQbMN00HwjxaAg2YN1o5QmAJNKDP\ntBII82EJNGBe6fhFxcbEji2SNKglnf50AFrQyhFCagk0d9/m7iPuPtIPP74B+lkrgdDXS6AB81HT\npwzzYAk0YN5p6RpC47fYlP6bbA788tpC9Wsey09MOrZpTbr2un8UmHL3v09mr2moTuRnVkrShQWC\n26924kSRJjrSAzqLexkABAIBQCAQAAQCAUAgEAAEAgFAIBAABAIBQCAQAAQCAUAo7dfBt9Oax97s\n2NhfbjyXrr1t61i69tgvvpeuHd59NF0rSVMH89Oi5UUWQ2U6cr/jCAFAIBAABAIBQCAQAAQCAUAg\nEAAEAgFAIBAABAIBQCAQAAQCAUDoi3sZOumGvyxM104dnvaLq2Z0YmN+6fjB48PpWklaeuBgvtgs\nX8u9DH2PIwQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAAEAgEAIFAABCYujyLxX/d25mBPT9l+MQt\n1UJDL7/6qqLdpNTPfJWu9ampjvSAzuIIAUAgEAAEAgFAIBAABAIBQCAQAAQCAUAgEAAEAgFAIBAA\nBKYuz6Ze68iw3/ntmXTtqXUDxQa/9pp06aGfXpeuvf6Ns+na6hvvpmuZ5tw7OEIAEAgEAKGlUwYz\nOyjptKSapCl3H2lHUwDK0Y5rCBvd/fM2jAOgZJwyAAitBoJLes3M9prZlisVmNkWMxs1s9Hzmmjx\n0wHopFZPGe5y9yNm9g1Jr5vZ++6+59ICd98maZskLbeV/LZQoIe1dITg7kcaH8ck7ZJ0ZzuaAlCO\npgPBzJaa2dDFx5LulbSvXY0B6L5WThmGJe0ys4vjPOfur7SlKwClaDoQ3P2ApO+3sZd5pfb+/nTt\n0KHFxQZfkH9Zr/lh/rLOqcP5ac7X/HtpurZ24mS6Fp3Fjx0BBAIBQCAQAAQCAUAgEAAEAgFAIBAA\nBAIBQCAQAAQCAUBg1eWyeH7KcP1sfrVjSZLlc/6Tj25L164q8G6ZWndTunbBfw7mB5ZUP/NVupYV\nnYvhCAFAIBAABAIBQCAQAAQCAUAgEAAEAgFAIBAABAIBQCAQAAQCAUDgXoa5oMB9DxfU05W3/mE8\n30bF0rXHb1+Wrh3fcHu6VpLW/P69dG3t5Kn8wIW/zv2HIwQAgUAAEAgEAIFAABAIBACBQAAQCAQA\ngUAAEAgEAIFAABC6P3XZktNf5+A0Ulu0KF3rExMFBs5PGS6qMj6ZrvWF1XTtwvH86zdwquD+rVqZ\nLq3W833UCizvrnotXWoLin2beS0/dru/TzhCABAIBACBQAAQCAQAgUAAEAgEAIFAABAIBACBQAAQ\nCAQAoatTl61SUWXx4lRtfTy/GnBRlaGhdG399On8uIsH8+MWmJ5aWbIkXStJtQI96/xUvo/xc+na\nFXu+TNcO3HFjulaStDD/trUlufebJFULrCpdO3Um38Ntt6RrJaly+Gi6tp6dbp18mTlCABBmDQQz\n225mY2a275JtK83sdTP7sPFxRWfbBNANmSOEHZI2XbZtq6Td7r5W0u7GcwBz3KyB4O57JB2/bPP9\nknY2Hu+U9ECb+wJQgmavIQy7+8UrH59KGm5TPwBK1PJFRXd3STOu0mBmW8xs1MxGJz1/lRpA9zUb\nCMfMbLUkNT6OzVTo7tvcfcTdRwYs/2M5AN3XbCC8JGlz4/FmSS+2px0AZcr82PF5SW9KutXMDpvZ\nw5KelPRjM/tQ0o8azwHMcbNO+XL3h2b4q3va3AuAknV16nJ9aFDjd383VTv4t7fyAxdcebaybGm6\ntsjU5frZ/EXTIivretGVdYvUF5iCW/vi8p8+f00LBfZvyT8LrECtYq+JDQykaysrrk7XVi1/tn16\n7VXpWkla/nl+2ncluQK1fZz7OjB1GUAgEAAEAgFAIBAABAIBQCAQAAQCAUAgEAAEAgFAIBAAhK5O\nXa6MT2rZ3o9TtbVqNT1ukWmyklT/8kSh+nQfBVYwLjK92M+ebaKbnNpnX+SLvV6gNr9/tZOn8uNK\nUr3AtO8C7w1bkP928MnJdO3yfx9L10qST+THHnwh95rYr3J1HCEACAQCgEAgAAgEAoBAIAAIBAKA\nQCAACAQCgEAgAAgEAoBAIAAIXb2XoQifKnBfQEH1iWLLfucHLnZPRVYnvxad6rlneihyT8WpgvdU\nJNU/OlSovjo0lK7907dfTdXdvehkqo4jBACBQAAQCAQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAA\nELo7ddkln+qBqbIFprMCLSv6fqtYunRJZSA3pHJjcoQAIBAIAAKBACAQCAACgQAgEAgAAoEAIBAI\nAAKBACAQCABC91ddLjAtE5iX6uVNrecIAUCYNRDMbLuZjZnZvku2PWFmR8zs7caf+zrbJoBuyBwh\n7JC06Qrbn3b39Y0/L7e3LQBlmDUQ3H2PpONd6AVAyVq5hvComb3TOKVY0baOAJSm2UB4RtLNktZL\nOirpqZkKzWyLmY2a2ehk/WyTnw5ANzQVCO5+zN1r7l6X9KykO7+mdpu7j7j7yEBlcbN9AuiCpgLB\nzFZf8vRBSftmqgUwd8w6McnMnpe0QdIqMzss6XFJG8xsvSSXdFDSIx3sEUCXzBoI7v7QFTb/sQO9\nAChZd6cum8kWdH+2NNCvzntuFXNXbjo0U5cBBAIBQCAQAAQCAUAgEAAEAgFAIBAABAIBQCAQAAQC\nAUDo/jxiY9VloF3qqqfqsus4c4QAIBAIAAKBACAQCAACgQAgEAgAAoEAIBAIAAKBACAQCAACgQAg\ndP9eBs/OqgbmJy/wPVJJ/p+evYOIIwQAgUAAEAgEAIFAABAIBACBQAAQCAQAgUAAEAgEAIFAABC6\nP3UZQNtU0pOSs+MBQAOBACAQCAACgQAgEAgAAoEAIBAIAAKBACAQCAACgQAgWJEVXlv+ZGafSTp0\nhb9aJenzrjXSXf28bxL7N1escfdrZyvqaiDM2ITZqLuPlN1HJ/TzvknsX7/hlAFAIBAAhF4JhG1l\nN9BB/bxvEvvXV3riGgKA3tArRwgAegCBACAQCAACgQAgEAgAwv8BSeXqLgoUMe0AAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94db8949b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将每一步存储的注意力权重组合到一起就形成了注意力矩阵，绘制为图\n",
    "plt.matshow(decoder_attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
