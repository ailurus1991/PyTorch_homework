{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/e/e7/集智AI学园首页左上角logo_2017.8.17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火炬上的深度学习（下）第三节：神经网络莫扎特"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后作业：使用 LSTM 编写一个国际姓氏生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在火炬课程中，我们学习了使用 LSTM 来生成 MIDI 音乐。这节课我们使用类似的方法，再创建一个 LSTM 国际起名大师！\n",
    "\n",
    "完成后的模型能够像下面这样使用，指定一个国家名，模型即生成几个属于这个国家的姓氏。\n",
    "\n",
    "```\n",
    "> python generate.py Russian\n",
    "Rovakov    Uantov    Shavakov\n",
    "\n",
    "> python generate.py German\n",
    "Gerren    Ereng    Rosher\n",
    "\n",
    "> python generate.py Spanish\n",
    "Salla    Parer    Allan\n",
    "\n",
    "> python generate.py Chinese\n",
    "Chan    Hang    Iun\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一步当然是引入PyTorch及相关包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "这次的数据仍然是18个文本文件，每个文件以“国家名字”命名，文件中存储了大量这个国家的姓氏。\n",
    "\n",
    "在读取这些数据前，为了简化神经网络的输入参数规模，我们把各国各语言人名都转化成用26个英文字母来表示，下面就是转换的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "6a9d80df-1d38-4c41-849c-95e38da98cc7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# all_letters 即课支持打印的字符+标点符号\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "# Plus EOS marker\n",
    "n_letters = len(all_letters) + 1 \n",
    "EOS = n_letters - 1\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicode_to_ascii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 `\"O'Néàl\"` 被转化成了以普通ASCII字符表示的 `O'Neal`。\n",
    "\n",
    "在上面的代码中，还要注意这么几个变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_letters:  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\n",
      "n_letters:  59\n",
      "EOS:  58\n"
     ]
    }
   ],
   "source": [
    "# 姓氏中所有的可视字符\n",
    "print('all_letters: ', all_letters)\n",
    "# 所有字符的长度 +1 EOS结束符\n",
    "print('n_letters: ', n_letters)\n",
    "# 结束符，没有实质内容\n",
    "print('EOS: ', EOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中 `all_letters` 包含了我们数据集中所有可能出现的字符，也就是“字符表”。\n",
    "`n_letters` 是字符表的长度，在本例中长度为59。`EOS` 的索引号为58，它在字符表中没有对应的字符，仅代表结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好处理数据的方法，下面就可以放心的读取数据了。\n",
    "\n",
    "我们建立一个列表 `all_categories` 用于存储所有的国家名字。\n",
    "\n",
    "建立一个字典 `category_lines`，以读取的国名作为字典的索引，国名下存储对应国别的名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories:  18 ['Spanish', 'Chinese', 'Italian', 'Portuguese', 'French', 'Japanese', 'Greek', 'German', 'Korean', 'Arabic', 'Russian', 'Vietnamese', 'Czech', 'Scottish', 'English', 'Dutch', 'Irish', 'Polish']\n",
      "\n",
      "# Russian names:  ['Ababko', 'Abaev', 'Abagyan', 'Abaidulin', 'Abaidullin', 'Abaimoff', 'Abaimov', 'Abakeliya', 'Abakovsky', 'Abakshin']\n"
     ]
    }
   ],
   "source": [
    "# 按行读取出文件中的名字，并返回包含所有名字的列表\n",
    "def read_lines(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "\n",
    "# category_lines是一个字典\n",
    "# 其中索引是国家名字，内容是从文件读取出的这个国家的所有名字\n",
    "category_lines = {}\n",
    "# all_categories是一个列表\n",
    "# 其中包含了所有的国家名字\n",
    "all_categories = []\n",
    "# 循环所有文件\n",
    "for filename in glob.glob('./names/*.txt'):\n",
    "    # 从文件名中切割出国家名字\n",
    "    category = filename.split('/')[-1].split('.')[0]\n",
    "    # 将国家名字添加到列表中\n",
    "    all_categories.append(category)\n",
    "    # 读取对应国别文件中所有的名字\n",
    "    lines = read_lines(filename)\n",
    "    # 将所有名字存储在字典中对应的国别下\n",
    "    category_lines[category] = lines\n",
    "\n",
    "# 共有的国别数\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print('# categories: ', n_categories, all_categories)\n",
    "print()\n",
    "print('# Russian names: ', category_lines['Russian'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n"
     ]
    }
   ],
   "source": [
    "# 再统计下手头共有多少条训练数据\n",
    "all_line_num = 0\n",
    "for key in category_lines:\n",
    "    all_line_num += len(category_lines[key])\n",
    "print(all_line_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们的数据准备好了，可以搭建神经网络了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立一个可以随机选择数据对 `(category, line)` 的方法，以方便训练时调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Greek', 'Polymenakou')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_training_pair():\n",
    "    # 随机选择一个国别名\n",
    "    category = random.choice(all_categories)\n",
    "    # 读取这个国别名下的所有人名\n",
    "    line = random.choice(category_lines[category])\n",
    "    return category, line\n",
    "\n",
    "print(random_training_pair())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先处理国别，将国别名转化为索引。\n",
    "\n",
    "这个索引是要和姓氏一起传入神经网络模型的。我们这次编写的是根据“国名条件”生成“符合条件的姓氏”的 LSTM 模型。这种将“条件”和“符合条件的数据”合并一起作为训练输入数据的方法，在“条件模型”里非常流行。\n",
    "\n",
    "比如 条件GAN（Conditional GAN），在训练时是把数据标签拼接到数据图片中一起进行训练的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 将名字所属的国家名转化为“独热向量”\n",
    "def make_category_input(category):\n",
    "    li = all_categories.index(category)\n",
    "    return  li\n",
    "\n",
    "print(make_category_input('Italian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "对于训练过程中的每一步，或者说对于训练数据中每个名字的每个字符来说，神经网络的输入是 `(category, current letter, hidden state)`，输出是 `(next letter, next hidden state)`。\n",
    "\n",
    "与在课程中讲的一样，神经网络还是依据“当前的字符”预测“下一个字符”。比如对于“Kasparov”这个名字，创建的（input, target）数据对是 (\"K\", \"a\"), (\"a\", \"s\"), (\"s\", \"p\"), (\"p\", \"a\"), (\"a\", \"r\"), (\"r\", \"o\"), (\"o\", \"v\"), (\"v\", \"EOS\")。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbpresent": {
     "id": "cf311809-10bf-40f7-87e1-1952342f7f35"
    }
   },
   "outputs": [],
   "source": [
    "def make_chars_input(nameStr):\n",
    "    name_char_list = list(map(lambda x: all_letters.find(x), nameStr))\n",
    "    return name_char_list\n",
    "\n",
    "\n",
    "def make_target(nameStr):\n",
    "    target_char_list = list(map(lambda x: all_letters.find(x), nameStr[1:]))\n",
    "    target_char_list.append(n_letters - 1)# EOS\n",
    "    return target_char_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样为了训练时方便使用，我们建立一个 `random_training_set` 函数，以随机选择出数据集 `(category, line)` 并转化成训练需要的 Tensor： `(category, input, target) `。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    # 随机选择数据集\n",
    "    category, line = random_training_pair()\n",
    "    #print(category, line)\n",
    "    # 转化成对应 Tensor\n",
    "    category_input = make_category_input(category)\n",
    "    line_input = make_chars_input(line)\n",
    "    #category_name_input = make_category_name_input(category, line)\n",
    "    line_target = make_target(line)\n",
    "    return category_input, line_input, line_target\n",
    "    #return category_name_input, line_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, [47, 0, 17, 6, 0, 18], [0, 17, 6, 0, 18, 58])\n"
     ]
    }
   ],
   "source": [
    "print(random_training_set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ff5f52a-2523-47f0-beba-f6c29d412e5f"
    }
   },
   "source": [
    "# 搭建神经网络\n",
    "\n",
    "这次使用的 LSTM 神经网络整体结构上与课上讲的生成音乐的模型非常相似，不过有一点请注意一下。\n",
    "\n",
    "我们要把国别和国别对应的姓氏一同输入到神经网络中，这样 LSTM 模型才能分别学习到每个国家姓氏的特色，从而生成不同国家不同特色的姓氏。\n",
    "\n",
    "那国别数据与姓氏数据应该如何拼接哪？应该在嵌入前拼接，还是在嵌入后再进行拼接哪？嵌入后的维度与 hidden_size 有怎样的关系哪？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要参考课上的模型，将这个模型补充完整。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个手动实现的LSTM模型，\n",
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, category_size, name_size, hidden_size, output_size, num_layers = 1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size \n",
    "        self.num_layers = num_layers\n",
    "       \n",
    "        # 进行嵌入\n",
    "        self.embedding_category = nn.Embedding(category_size,\n",
    "                                               hidden_size)\n",
    "        self.embedding_name = nn.Embedding(name_size,\n",
    "                                           hidden_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 隐含层内部的相互链接\n",
    "        self.lstm = nn.LSTM(hidden_size*2,\n",
    "                            hidden_size,\n",
    "                            num_layers,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        # 输出层\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "\n",
    "    def forward(self, category_variable, name_variable, hidden):\n",
    "        \n",
    "        # 先分别进行embedding层的计算\n",
    "        category_embed = self.embedding_category(category_variable)\n",
    "        name_embed = self.embedding_name(name_variable)\n",
    "        \n",
    "        \n",
    "        # 从输入到隐含层的计算\n",
    "        input_concat = torch.cat([category_embed, name_embed]).view(2 * self.hidden_size, -1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # output的尺寸：batch_size, len_seq, hidden_size\n",
    "        output, hidden = self.lstm(input_concat, hidden)\n",
    "        # last step\n",
    "        output = output[:, -1, :]\n",
    "    \n",
    "        \n",
    "        # 全连接层\n",
    "        output = self.fc(output)\n",
    "\n",
    "        # output的尺寸：batch_size, output_size\n",
    "\n",
    "        # softmax函数\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output, hidden\n",
    " \n",
    "    def initHidden(self):\n",
    "        # 对隐含单元的初始化\n",
    "        # 注意尺寸是： layer_size, batch_size, hidden_size\n",
    "        # 对隐单元的初始化\n",
    "        # 对引单元输出的初始化，全0.\n",
    "        # 注意hidden和cell的维度都是layers,batch_size,hidden_size\n",
    "        hidden = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        # 对隐单元内部的状态cell的初始化，全0\n",
    "        cell = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        return (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与之前处理得分类问题不同，在分类问题中只有最后的输出被使用。而在当前的 **生成** 姓氏的任务中，神经网络在每一步都会做预测，所以我们需要在每一步计算损失值。\n",
    "\n",
    "PyTorch 非常易用，它允许我们只是简单的把每一步计算的损失加起来，在遍历完一个姓氏后，再进行反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要将训练函数补充完整，或者编写自己的训练函数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数，在这个函数里，我们可以随机选择一条训练数据，遍历每个字符进行训练\n",
    "def train_LSTM():\n",
    "    # 初始化 隐藏层、梯度清零、损失清零\n",
    "    hidden = lstm.initHidden()\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 随机选取一条训练数据\n",
    "    category_input, line_input, line_target =  random_training_set()\n",
    "    # 处理国别数据\n",
    "    category_variable = Variable(torch.LongTensor([category_input]))\n",
    "    \n",
    "    # 循环字符\n",
    "    for t in range(len(line_input)):\n",
    "        # 姓氏\n",
    "        name_variable = Variable(torch.LongTensor([line_input[t]]))\n",
    "        # 目标\n",
    "        target_variable = Variable(torch.LongTensor([line_target[t]]))\n",
    "        \n",
    "        # 传入模型\n",
    "        output, hidden = lstm(category_variable, name_variable, hidden)\n",
    "        \n",
    "        # 累加损失\n",
    "        loss += criterion(output, target_variable)\n",
    "        \n",
    "    \n",
    "    # 计算平均损失\n",
    "    loss = 1.0 * loss / len(line_input)\n",
    "    \n",
    "    # 反向传播、更新梯度\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义 `time_since` 函数，它可以打印出训练持续的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(t):\n",
    "    now = time.time()\n",
    "    s = now - t\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在下面你要定义损失函数、优化函数、实例化模型参数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 32\n",
    "num_epoch = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 实例化模型\n",
    "lstm = LSTMNetwork(category_size=18,\n",
    "                   name_size=58,\n",
    "                   hidden_size=HIDDEN_SIZE,\n",
    "                   output_size=59)\n",
    "\n",
    "# 定义损失函数与优化方法\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的过程与我们前几节课一样，都是老套路啦！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，训练损失：2.55，训练进度：2.99%，（0m 43s）\n",
      "第0轮，训练损失：2.37，训练进度：5.98%，（1m 19s）\n",
      "第0轮，训练损失：2.27，训练进度：8.97%，（1m 57s）\n",
      "第0轮，训练损失：2.20，训练进度：11.96%，（2m 36s）\n",
      "第0轮，训练损失：2.14，训练进度：14.94%，（3m 14s）\n",
      "第0轮，训练损失：2.10，训练进度：17.93%，（3m 50s）\n",
      "第1轮，训练损失：1.86，训练进度：22.99%，（4m 59s）\n",
      "第1轮，训练损失：1.83，训练进度：25.98%，（5m 37s）\n",
      "第1轮，训练损失：1.82，训练进度：28.97%，（6m 16s）\n",
      "第1轮，训练损失：1.81，训练进度：31.96%，（6m 53s）\n",
      "第1轮，训练损失：1.80，训练进度：34.94%，（7m 31s）\n",
      "第1轮，训练损失：1.79，训练进度：37.93%，（8m 9s）\n",
      "第2轮，训练损失：1.73，训练进度：42.99%，（9m 16s）\n",
      "第2轮，训练损失：1.71，训练进度：45.98%，（9m 54s）\n",
      "第2轮，训练损失：1.71，训练进度：48.97%，（10m 32s）\n",
      "第2轮，训练损失：1.70，训练进度：51.96%，（11m 11s）\n",
      "第2轮，训练损失：1.70，训练进度：54.94%，（11m 50s）\n",
      "第2轮，训练损失：1.69，训练进度：57.93%，（12m 28s）\n",
      "第3轮，训练损失：1.65，训练进度：62.99%，（13m 35s）\n",
      "第3轮，训练损失：1.65，训练进度：65.98%，（14m 14s）\n",
      "第3轮，训练损失：1.64，训练进度：68.97%，（14m 52s）\n",
      "第3轮，训练损失：1.64，训练进度：71.96%，（15m 30s）\n",
      "第3轮，训练损失：1.63，训练进度：74.94%，（16m 8s）\n",
      "第3轮，训练损失：1.62，训练进度：77.93%，（16m 46s）\n",
      "第4轮，训练损失：1.59，训练进度：82.99%，（17m 53s）\n",
      "第4轮，训练损失：1.59，训练进度：85.98%，（18m 31s）\n",
      "第4轮，训练损失：1.58，训练进度：88.97%，（19m 10s）\n",
      "第4轮，训练损失：1.59，训练进度：91.96%，（19m 47s）\n",
      "第4轮，训练损失：1.59，训练进度：94.94%，（20m 26s）\n",
      "第4轮，训练损失：1.58，训练进度：97.93%，（21m 4s）\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "records = []\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = 0\n",
    "    # 按所有数据的行数随机循环\n",
    "    for i in range(all_line_num):\n",
    "        loss = train_LSTM()\n",
    "        train_loss += loss\n",
    "        \n",
    "        #每隔3000步，跑一次校验集，并打印结果\n",
    "        if i % 3000 == 0 and i != 0:\n",
    "            training_process = (all_line_num * epoch + i) / (all_line_num * num_epoch) * 100\n",
    "            training_process = '%.2f' % training_process\n",
    "            print('第{}轮，训练损失：{:.2f}，训练进度：{}%，（{}）'\\\n",
    "                .format(epoch, train_loss.data.numpy()[0] / i, float(training_process), time_since(start)))\n",
    "            records.append([train_loss.data.numpy()[0] / i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制观察损失曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们将训练过程中记录的损失绘制成一条曲线，观察下神经网络学习的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f73eccd02b0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAELCAYAAAA2mZrgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np1AQEZF2CgUREWmnUBARkXb/H/WyJbIH+3xsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7273563400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "a = [i[0] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我在计算损失平均值时有“除0错误”，所以在损失曲线中有间断，大家可以改进我的计算方法，让损失曲线连贯起来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试使用神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然神经网络训练好了，那也就是说，我们喂给它第一个字符，他就能生成第二个字符，喂给它第二个字符，它就会生成第三个，这样一直持续下去，直至生成 EOS 才结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那下面我们编写 `generate_one` 函数以方便的使用神经网络生成我们想要的名字字符串，在这个函数里我们定义以下内容：\n",
    "\n",
    "* 建立输入国别，开始字符，初始隐藏层状态的 Tensor\n",
    "* 创建 `output_str` 变量，创建时其中只包含“开始字符”\n",
    "* 定义生成名字的长度最大不超过 `max_length`\n",
    "    * 将当前字符传入神经网络\n",
    "    * 在输出中选出预测的概率最大的下一个字符，同时取出当前的隐藏层状态\n",
    "    * 如果字符是 EOS，则生成结束\n",
    "    * 如果是常规字符，则加入到 `output_str` 中并继续下一个流程\n",
    "* 返回最终生成的名字字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要自行编写模型验证方法。 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# 通过指定国别名 category\n",
    "# 以及开始字符 start_char\n",
    "# 还有混乱度 temperature 来生成一个名字\n",
    "def generate_one(category, start_char='A', temperature=0.2):\n",
    "    # 初始化输入数据，国别 以及 输入的第一个字符\n",
    "    # 国别\n",
    "    category_input = make_category_input(category)\n",
    "    category_variable = Variable(torch.LongTensor([category_input]))\n",
    "    # 第一个字符\n",
    "    char_input = all_letters.index(start_char)\n",
    "    char_variable = Variable(torch.LongTensor([char_input]))\n",
    "   \n",
    "    # 初始化隐藏层\n",
    "    hidden = lstm.initHidden()\n",
    "    \n",
    "    output_str = start_char\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        \n",
    "        # 调用模型\n",
    "        output, hidden = lstm(category_variable,\n",
    "                              char_variable,\n",
    "                              hidden)\n",
    "        \n",
    "        # 这里是将输出转化为一个多项式分布\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        # 从而可以根据混乱度 temperature 来选择下一个字符\n",
    "        # 混乱度低，则趋向于选择网络预测最大概率的那个字符\n",
    "        # 混乱度高，则趋向于随机选择字符\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # 生成字符是 EOS，则生成结束\n",
    "        if top_i == EOS:\n",
    "            break\n",
    "        else:\n",
    "            # 继续下一个字符\n",
    "            char = all_letters[top_i]\n",
    "            output_str += char\n",
    "            chars_input = all_letters.index(char)\n",
    "            char_variable = Variable(torch.LongTensor([chars_input]))\n",
    "            \n",
    "    return output_str\n",
    "\n",
    "# 再定义一个函数，方便每次生成多个名字\n",
    "def generate(category, start_chars='ABC', temperature=0.2):\n",
    "    for start_char in start_chars:\n",
    "        print(generate_one(category, start_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rin\n",
      "Uzhev\n",
      "Shakhin\n"
     ]
    }
   ],
   "source": [
    "generate('Russian', 'RUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorn\n",
      "Eitz\n",
      "Rotz\n"
     ]
    }
   ],
   "source": [
    "generate('German', 'GER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Santa\n",
      "Pina\n",
      "Abarria\n"
     ]
    }
   ],
   "source": [
    "generate('Spanish', 'SPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ching\n",
      "Hou\n",
      "Ii\n"
     ]
    }
   ],
   "source": [
    "generate('Chinese', 'CHI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 LSTM 预测的效果，但显然还不理想，我想你可以通过调整网络模型，或者通过调整超参数让模型表现的更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/c/ca/AI学园.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "10393c05-7962-4245-9228-8b7db4eb79a1": {
     "id": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "prev": "22628fc4-8309-4579-ba36-e5b01a841473",
     "regions": {
      "335fd672-4ee6-4b7c-a65f-3ecbf38305e1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cc294dae-dd8f-4288-8d3c-bb9fd3ad19bc",
        "part": "whole"
       },
       "id": "335fd672-4ee6-4b7c-a65f-3ecbf38305e1"
      }
     }
    },
    "22628fc4-8309-4579-ba36-e5b01a841473": {
     "id": "22628fc4-8309-4579-ba36-e5b01a841473",
     "prev": null,
     "regions": {
      "6cfa5157-02f6-48e3-8ce4-89641febbe59": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9a73330c-27c1-4957-8e95-c3b42bc14a71",
        "part": "whole"
       },
       "id": "6cfa5157-02f6-48e3-8ce4-89641febbe59"
      }
     }
    },
    "2f34f0df-3ccc-4416-9d5d-cb4b075f539f": {
     "id": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "prev": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "regions": {
      "e25707b9-630e-4ece-9f66-bfcbc8342d76": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "df50f546-6d02-4383-beab-90378f16576b",
        "part": "whole"
       },
       "id": "e25707b9-630e-4ece-9f66-bfcbc8342d76"
      }
     }
    },
    "3eb7f63f-04de-4f51-a240-38d5074bed6f": {
     "id": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "prev": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "regions": {
      "76282c28-a6ba-4a08-be6c-4f27f5b81ddf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "53fb987f-4f42-4bf8-81ae-280ebdd19aee",
        "part": "whole"
       },
       "id": "76282c28-a6ba-4a08-be6c-4f27f5b81ddf"
      }
     }
    },
    "686bcaec-0623-4943-b227-f4e1c5975c4a": {
     "id": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "prev": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "regions": {
      "659c021e-7f79-4612-aa7d-8f1c48f91f8b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4ff5f52a-2523-47f0-beba-f6c29d412e5f",
        "part": "whole"
       },
       "id": "659c021e-7f79-4612-aa7d-8f1c48f91f8b"
      }
     }
    },
    "964ac1b6-c781-47e8-89f0-1f593d473cd0": {
     "id": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "prev": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "regions": {
      "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8ff6da45-57cd-46ca-b14a-3f560ce4d345",
        "part": "whole"
       },
       "id": "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5"
      }
     }
    },
    "cc4bd43a-59ec-4127-b1d8-ebd30162207a": {
     "id": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "prev": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "regions": {
      "1e6711af-7711-4579-ac7a-f893b0d86931": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cf311809-10bf-40f7-87e1-1952342f7f35",
        "part": "whole"
       },
       "id": "1e6711af-7711-4579-ac7a-f893b0d86931"
      }
     }
    },
    "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8": {
     "id": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "prev": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "regions": {
      "3b983e72-35fb-4d19-83b4-789a3394f61f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "597a765d-634b-41a8-a0c6-be5c019da150",
        "part": "whole"
       },
       "id": "3b983e72-35fb-4d19-83b4-789a3394f61f"
      }
     }
    },
    "e4c6fc30-f833-4368-99fe-5297b99f1f14": {
     "id": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "prev": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "regions": {
      "98a6b3b6-d2db-4d8a-bb16-a4307ede4803": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6a9d80df-1d38-4c41-849c-95e38da98cc7",
        "part": "whole"
       },
       "id": "98a6b3b6-d2db-4d8a-bb16-a4307ede4803"
      }
     }
    },
    "f1a487d8-4b0b-47df-988f-1161d66174b2": {
     "id": "f1a487d8-4b0b-47df-988f-1161d66174b2",
     "prev": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "regions": {
      "2c817a32-203d-404b-8bf5-ba17f7d27034": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "81fde336-785e-461b-a751-718a5f6bff88",
        "part": "whole"
       },
       "id": "2c817a32-203d-404b-8bf5-ba17f7d27034"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
