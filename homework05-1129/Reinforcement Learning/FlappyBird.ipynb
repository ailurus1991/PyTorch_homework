{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度强化学习－用卷积神经网络实现AI玩Flappy Bird游戏\n",
    "\n",
    "本节课我们结合Flappy bird游戏，详细讲述了深度强化学习原理，以及如何训练一个神经网络来玩儿游戏\n",
    "\n",
    "整个代码包括了利用PyGame包实现一个Flappy Bird游戏，卷积神经网络的定义与实现，以及深度强化学习算法。\n",
    "\n",
    "本程序参考了AI玩Flappy Bird的TensorFlow版本：https://github.com/yenchenlin/DeepLearningFlappyBird\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第X课的配套源代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、PyGAME实现Flappy Bird游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这部分中，我们调用PyGame包实现了一个Flappy Bird游戏。通过PyGame，我们可以非常方便的加载图片、音频，来快速实现小游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 加载游戏所需的必要资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载游戏中的所有资源，包括图片以及音频\n",
    "# 调用PyGame包，关于该包的安装，请参看：http://www.pygame.org/wiki/GettingStarted\n",
    "import pygame\n",
    "\n",
    "# 需要获取操作系统类型，故而调用sys包\n",
    "import sys\n",
    "def load():\n",
    "    # 加载各类资源的函数\n",
    "    # 精灵在不同状态下的图片\n",
    "    PLAYER_PATH = (\n",
    "            'assets/sprites/redbird-upflap.png',\n",
    "            'assets/sprites/redbird-midflap.png',\n",
    "            'assets/sprites/redbird-downflap.png'\n",
    "    )\n",
    "\n",
    "    # 背景图地址\n",
    "    BACKGROUND_PATH = 'assets/sprites/background-black.png'\n",
    "\n",
    "    # 管道图片所在的地址\n",
    "    PIPE_PATH = 'assets/sprites/pipe-green.png'\n",
    "\n",
    "    IMAGES, SOUNDS, HITMASKS = {}, {}, {}\n",
    "\n",
    "    # 加载成绩数字所需的图片\n",
    "    IMAGES['numbers'] = (\n",
    "        pygame.image.load('assets/sprites/0.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/1.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/2.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/3.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/4.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/5.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/6.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/7.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/8.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/9.png').convert_alpha()\n",
    "    )\n",
    "\n",
    "    # 加载地面的图片\n",
    "    IMAGES['base'] = pygame.image.load('assets/sprites/base.png').convert_alpha()\n",
    "\n",
    "    # 加载声音文件（在不同的系统中，声音文件扩展名不同）\n",
    "    if 'win' in sys.platform:\n",
    "        soundExt = '.wav'\n",
    "    else:\n",
    "        soundExt = '.ogg'\n",
    "\n",
    "    SOUNDS['die']    = pygame.mixer.Sound('assets/audio/die' + soundExt)\n",
    "    SOUNDS['hit']    = pygame.mixer.Sound('assets/audio/hit' + soundExt)\n",
    "    SOUNDS['point']  = pygame.mixer.Sound('assets/audio/point' + soundExt)\n",
    "    SOUNDS['swoosh'] = pygame.mixer.Sound('assets/audio/swoosh' + soundExt)\n",
    "    SOUNDS['wing']   = pygame.mixer.Sound('assets/audio/wing' + soundExt)\n",
    "\n",
    "    # 加载背景图\n",
    "    IMAGES['background'] = pygame.image.load(BACKGROUND_PATH).convert()\n",
    "\n",
    "    # s加载精灵图\n",
    "    IMAGES['player'] = (\n",
    "        pygame.image.load(PLAYER_PATH[0]).convert_alpha(),\n",
    "        pygame.image.load(PLAYER_PATH[1]).convert_alpha(),\n",
    "        pygame.image.load(PLAYER_PATH[2]).convert_alpha(),\n",
    "    )\n",
    "\n",
    "    # 加载水管\n",
    "    IMAGES['pipe'] = (\n",
    "        pygame.transform.rotate(\n",
    "            pygame.image.load(PIPE_PATH).convert_alpha(), 180),\n",
    "        pygame.image.load(PIPE_PATH).convert_alpha(),\n",
    "    )\n",
    "\n",
    "    # 获得水管的蒙板\n",
    "    HITMASKS['pipe'] = (\n",
    "        getHitmask(IMAGES['pipe'][0]),\n",
    "        getHitmask(IMAGES['pipe'][1]),\n",
    "    )\n",
    "\n",
    "    # 玩家的蒙板\n",
    "    HITMASKS['player'] = (\n",
    "        getHitmask(IMAGES['player'][0]),\n",
    "        getHitmask(IMAGES['player'][1]),\n",
    "        getHitmask(IMAGES['player'][2]),\n",
    "    )\n",
    "\n",
    "    #返回了三个字典，每个字典的值分别存储图像、声音和蒙板\n",
    "    return IMAGES, SOUNDS, HITMASKS\n",
    "\n",
    "def getHitmask(image):\n",
    "    \"\"\"根据图像的alpha，获得蒙板\"\"\"\n",
    "    #所谓蒙板就是指将图像中的主体从整个图像中抠出来的技术，从而方便与其它的对象合成到一起\n",
    "    #蒙板用一个boolean类型的列表来存储\n",
    "    mask = []\n",
    "    for x in range(image.get_width()):\n",
    "        mask.append([])\n",
    "        for y in range(image.get_height()):\n",
    "            mask[x].append(bool(image.get_at((x,y))[3]))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "video system not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-30975b609c9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: video system not initialized"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "pygame.init()\n",
    "pygame.display.list_modes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 实现Flappy Bird的游戏逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "video system not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63de0af0415c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mFPSCLOCK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#定义程序时钟\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: video system not initialized"
     ]
    }
   ],
   "source": [
    "# 加载程序所需的包\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import pygame\n",
    "import pygame.surfarray as surfarray\n",
    "from pygame.locals import *\n",
    "from itertools import cycle\n",
    "FPS = 30 #帧率\n",
    "SCREENWIDTH  = 288 #屏幕的宽度\n",
    "SCREENHEIGHT = 512 #屏幕的高度\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "FPSCLOCK = pygame.time.Clock() #定义程序时钟\n",
    "SCREEN = pygame.display.set_mode((SCREENWIDTH, SCREENHEIGHT)) #定义屏幕对象\n",
    "pygame.display.set_caption('Flappy Bird') #设定窗口名称\n",
    "\n",
    "IMAGES, SOUNDS, HITMASKS = load() #加载游戏资源\n",
    "PIPEGAPSIZE = 100 # 定义两个水管之间的宽度\n",
    "BASEY = SCREENHEIGHT * 0.79 #设定基地的高度\n",
    "\n",
    "# 设定小鸟属性：宽度、高度等\n",
    "PLAYER_WIDTH = IMAGES['player'][0].get_width()\n",
    "PLAYER_HEIGHT = IMAGES['player'][0].get_height()\n",
    "\n",
    "# 设定水管属性：高度、宽度\n",
    "PIPE_WIDTH = IMAGES['pipe'][0].get_width()\n",
    "PIPE_HEIGHT = IMAGES['pipe'][0].get_height()\n",
    "\n",
    "#背景宽度\n",
    "BACKGROUND_WIDTH = IMAGES['background'].get_width()\n",
    "\n",
    "PLAYER_INDEX_GEN = cycle([0, 1, 2, 1])\n",
    "\n",
    "# 游戏模型类\n",
    "class GameState:\n",
    "    def __init__(self):\n",
    "        # 初始化\n",
    "        # 初始成绩、玩家索引、循环迭代都为0\n",
    "        self.score = self.playerIndex = self.loopIter = 0\n",
    "        \n",
    "        #设定玩家的初始位置\n",
    "        self.playerx = int(SCREENWIDTH * 0.2)\n",
    "        self.playery = int((SCREENHEIGHT - PLAYER_HEIGHT) / 2)\n",
    "        self.basex = 0\n",
    "        # 地面的初始移位\n",
    "        self.baseShift = IMAGES['base'].get_width() - BACKGROUND_WIDTH\n",
    "\n",
    "        # 生成两个随机的水管\n",
    "        newPipe1 = getRandomPipe()\n",
    "        newPipe2 = getRandomPipe()\n",
    "        \n",
    "        # 设定初始水管的位置x，y坐标\n",
    "        self.upperPipes = [\n",
    "            {'x': SCREENWIDTH, 'y': newPipe1[0]['y']},\n",
    "            {'x': SCREENWIDTH + (SCREENWIDTH / 2), 'y': newPipe2[0]['y']},\n",
    "        ]\n",
    "        self.lowerPipes = [\n",
    "            {'x': SCREENWIDTH, 'y': newPipe1[1]['y']},\n",
    "            {'x': SCREENWIDTH + (SCREENWIDTH / 2), 'y': newPipe2[1]['y']},\n",
    "        ]\n",
    "\n",
    "        # 定义玩家的属性\n",
    "        self.pipeVelX = -4\n",
    "        self.playerVelY    =  0    # 小鸟在y轴上的速度，初始设置维playerFlapped\n",
    "        self.playerMaxVelY =  10   # Y轴上的最大速度, 也就是最大的下降速度\n",
    "        self.playerMinVelY =  -8   # Y轴向上的最大速度\n",
    "        self.playerAccY    =   1   # 小鸟往下落的加速度\n",
    "        self.playerFlapAcc =  -9   # 扇动翅膀的加速度\n",
    "        self.playerFlapped = False # 玩家是否煽动了翅膀\n",
    "\n",
    "    def frame_step(self, input_actions):\n",
    "        # input_actions是一个行动数组，分别存储了0或者1两个动作的激活情况\n",
    "        # 游戏每一帧的循环\n",
    "        pygame.event.pump()\n",
    "\n",
    "        # 每一步的默认回报\n",
    "        reward = 0.1\n",
    "        terminal = False\n",
    "\n",
    "        # 限定每一帧只能做一个动作\n",
    "        if sum(input_actions) != 1:\n",
    "            raise ValueError('Multiple input actions!')\n",
    "\n",
    "        # input_actions[0] == 1: 对应什么都不做\n",
    "        # input_actions[1] == 1: 对应小鸟煽动了翅膀\n",
    "        if input_actions[1] == 1:\n",
    "            # 小鸟煽动翅膀向上\n",
    "            if self.playery > -2 * PLAYER_HEIGHT:\n",
    "                self.playerVelY = self.playerFlapAcc\n",
    "                self.playerFlapped = True\n",
    "                #SOUNDS['wing'].play()\n",
    "\n",
    "        # 检查是否通过了管道，如果通过，则增加成绩\n",
    "        playerMidPos = self.playerx + PLAYER_WIDTH / 2\n",
    "        for pipe in self.upperPipes:\n",
    "            pipeMidPos = pipe['x'] + PIPE_WIDTH / 2\n",
    "            if pipeMidPos <= playerMidPos < pipeMidPos + 4:\n",
    "                self.score += 1\n",
    "                #SOUNDS['point'].play()\n",
    "                reward = 1\n",
    "\n",
    "        # playerIndex轮换\n",
    "        if (self.loopIter + 1) % 3 == 0:\n",
    "            self.playerIndex = next(PLAYER_INDEX_GEN)\n",
    "        self.loopIter = (self.loopIter + 1) % 30\n",
    "        self.basex = -((-self.basex + 100) % self.baseShift)\n",
    "\n",
    "        # 小鸟运动\n",
    "        if self.playerVelY < self.playerMaxVelY and not self.playerFlapped:\n",
    "            self.playerVelY += self.playerAccY\n",
    "        if self.playerFlapped:\n",
    "            self.playerFlapped = False\n",
    "        self.playery += min(self.playerVelY, BASEY - self.playery - PLAYER_HEIGHT)\n",
    "        if self.playery < 0:\n",
    "            self.playery = 0\n",
    "\n",
    "        # 管道的移动\n",
    "        for uPipe, lPipe in zip(self.upperPipes, self.lowerPipes):\n",
    "            uPipe['x'] += self.pipeVelX\n",
    "            lPipe['x'] += self.pipeVelX\n",
    "\n",
    "        # 当管道快到左侧边缘的时候，产生新的管道\n",
    "        if 0 < self.upperPipes[0]['x'] < 5:\n",
    "            newPipe = getRandomPipe()\n",
    "            self.upperPipes.append(newPipe[0])\n",
    "            self.lowerPipes.append(newPipe[1])\n",
    "\n",
    "        # 当第一个管道移出屏幕的时候，就把它删除\n",
    "        if self.upperPipes[0]['x'] < -PIPE_WIDTH:\n",
    "            self.upperPipes.pop(0)\n",
    "            self.lowerPipes.pop(0)\n",
    "\n",
    "        # 检查碰撞\n",
    "        isCrash= checkCrash({'x': self.playerx, 'y': self.playery,\n",
    "                             'index': self.playerIndex},\n",
    "                            self.upperPipes, self.lowerPipes)\n",
    "        # 如果有碰撞发生，则游戏结束，terminal＝True\n",
    "        if isCrash:\n",
    "            #SOUNDS['hit'].play()\n",
    "            #SOUNDS['die'].play()\n",
    "            terminal = True\n",
    "            self.__init__()\n",
    "            reward = -1\n",
    "\n",
    "        # 将所有角色都根据每个角色的坐标画到屏幕上\n",
    "        SCREEN.blit(IMAGES['background'], (0,0))\n",
    "\n",
    "        for uPipe, lPipe in zip(self.upperPipes, self.lowerPipes):\n",
    "            SCREEN.blit(IMAGES['pipe'][0], (uPipe['x'], uPipe['y']))\n",
    "            SCREEN.blit(IMAGES['pipe'][1], (lPipe['x'], lPipe['y']))\n",
    "\n",
    "        SCREEN.blit(IMAGES['base'], (self.basex, BASEY))\n",
    "        \n",
    "        # print score so player overlaps the score\n",
    "        # showScore(self.score)\n",
    "        SCREEN.blit(IMAGES['player'][self.playerIndex],\n",
    "                    (self.playerx, self.playery))\n",
    "\n",
    "        # 将当前的游戏屏幕生成一个二维画面返回\n",
    "        image_data = pygame.surfarray.array3d(pygame.display.get_surface())\n",
    "        pygame.display.update()\n",
    "        FPSCLOCK.tick(FPS)\n",
    "        #print self.upperPipes[0]['y'] + PIPE_HEIGHT - int(BASEY * 0.2)\n",
    "        # 该函数的输出有三个变量：游戏当前帧的游戏画面，当前获得的游戏得分，游戏是否已经结束\n",
    "        return image_data, reward, terminal\n",
    "    \n",
    "\n",
    "def getRandomPipe():\n",
    "    #随机生成管道的函数\n",
    "    \"\"\"returns a randomly generated pipe\"\"\"\n",
    "    # 两个管道之间的竖直间隔从下列数中直接取\n",
    "    gapYs = [20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    index = random.randint(0, len(gapYs)-1)\n",
    "    gapY = gapYs[index]\n",
    "\n",
    "    #设定新生成管道的位置\n",
    "    gapY += int(BASEY * 0.2)\n",
    "    pipeX = SCREENWIDTH + 10\n",
    "\n",
    "    # 返回管道的坐标\n",
    "    return [\n",
    "        {'x': pipeX, 'y': gapY - PIPE_HEIGHT},  # upper pipe\n",
    "        {'x': pipeX, 'y': gapY + PIPEGAPSIZE},  # lower pipe\n",
    "    ]\n",
    "\n",
    "\n",
    "def showScore(score):\n",
    "    # 在屏幕上直接展示成绩的函数\n",
    "    \"\"\"displays score in center of screen\"\"\"\n",
    "    scoreDigits = [int(x) for x in list(str(score))]\n",
    "    totalWidth = 0 # total width of all numbers to be printed\n",
    "\n",
    "    for digit in scoreDigits:\n",
    "        totalWidth += IMAGES['numbers'][digit].get_width()\n",
    "\n",
    "    Xoffset = (SCREENWIDTH - totalWidth) / 2\n",
    "\n",
    "    for digit in scoreDigits:\n",
    "        SCREEN.blit(IMAGES['numbers'][digit], (Xoffset, SCREENHEIGHT * 0.1))\n",
    "        Xoffset += IMAGES['numbers'][digit].get_width()\n",
    "\n",
    "\n",
    "def checkCrash(player, upperPipes, lowerPipes):\n",
    "    # 检测碰撞的函数，基本思路为：将每一个物体都看作是一个矩形区域，然后检查两个矩形区域是否有碰撞\n",
    "    # 检查碰撞是细到每个对象的图像蒙板级别，而不单纯是看矩形之间的碰撞\n",
    "    \"\"\"returns True if player collders with base or pipes.\"\"\"\n",
    "    pi = player['index']\n",
    "    player['w'] = IMAGES['player'][0].get_width()\n",
    "    player['h'] = IMAGES['player'][0].get_height()\n",
    "\n",
    "    # 检查小鸟是否碰撞到了地面\n",
    "    if player['y'] + player['h'] >= BASEY - 1:\n",
    "        return True\n",
    "    else:\n",
    "        # 检查小鸟是否与管道碰撞\n",
    "        playerRect = pygame.Rect(player['x'], player['y'],\n",
    "                      player['w'], player['h'])\n",
    "\n",
    "        for uPipe, lPipe in zip(upperPipes, lowerPipes):\n",
    "            # 上下管道矩形\n",
    "            uPipeRect = pygame.Rect(uPipe['x'], uPipe['y'], PIPE_WIDTH, PIPE_HEIGHT)\n",
    "            lPipeRect = pygame.Rect(lPipe['x'], lPipe['y'], PIPE_WIDTH, PIPE_HEIGHT)\n",
    "\n",
    "            # 获得每个元素的蒙板\n",
    "            pHitMask = HITMASKS['player'][pi]\n",
    "            uHitmask = HITMASKS['pipe'][0]\n",
    "            lHitmask = HITMASKS['pipe'][1]\n",
    "\n",
    "            # 检查是否与上下管道相撞\n",
    "            uCollide = pixelCollision(playerRect, uPipeRect, pHitMask, uHitmask)\n",
    "            lCollide = pixelCollision(playerRect, lPipeRect, pHitMask, lHitmask)\n",
    "\n",
    "            if uCollide or lCollide:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def pixelCollision(rect1, rect2, hitmask1, hitmask2):\n",
    "    \"\"\"在像素级别检查两个物体是否发生碰撞\"\"\"\n",
    "    rect = rect1.clip(rect2)\n",
    "\n",
    "    if rect.width == 0 or rect.height == 0:\n",
    "        return False\n",
    "\n",
    "    # 确定矩形框，并针对矩形框中的每个像素进行循环，查看两个对象是否碰撞\n",
    "    x1, y1 = rect.x - rect1.x, rect.y - rect1.y\n",
    "    x2, y2 = rect.x - rect2.x, rect.y - rect2.y\n",
    "\n",
    "    for x in range(rect.width):\n",
    "        for y in range(rect.height):\n",
    "            if hitmask1[x1+x][y1+y] and hitmask2[x2+x][y2+y]:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 对游戏做小测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f211845ad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# 新建一个游戏\n",
    "game = GameState()\n",
    "\n",
    "fig = plt.figure()\n",
    "axe = fig.add_subplot(111)\n",
    "dat = np.zeros((10, 10))\n",
    "img = axe.imshow(dat)\n",
    "\n",
    "# 进行100步循环，并将每一帧的画面打印出来\n",
    "for i in range(100):\n",
    "    clear_output(wait = True)\n",
    "    image_data, reward, terminal = game.frame_step([0,1])\n",
    "    \n",
    "    image = np.transpose(image_data, (1, 0, 2))\n",
    "    img.set_data(image)\n",
    "    img.autoscale()\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、训练神经网络玩游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  导入必需的包\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2 #需要安装OpenCV的包\n",
    "import sys\n",
    "sys.path.append(\"game/\")\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# 定义一系列常数，其中，epsilon为每周期随机输出一个动作的概率\n",
    "GAME = 'bird' # 游戏名称\n",
    "ACTIONS = 2 # 有效输出动作的个数\n",
    "GAMMA = 0.99 # 强化学习中未来的衰减率\n",
    "OBSERVE = 10000. # 训练之前的时间步，需要先观察10000帧\n",
    "EXPLORE = 3000000. # 退火所需的时间步，所谓的退火就是指随机选择率epsilon逐渐变小\n",
    "FINAL_EPSILON = 0.0001 # epsilon的最终值\n",
    "INITIAL_EPSILON = 0.1 # epsilon的初始值\n",
    "REPLAY_MEMORY = 50000 # 最多记忆多少帧训练数据\n",
    "BATCH = 32 # 每一个批次的数据记录条数\n",
    "FRAME_PER_ACTION = 1 # 每间隔多少时间完成一次有效动作的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建一个多层CNN网络，该网络接收的输入为4帧画面，输出为每个可能动作对应的Q函数值\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 第一层卷积，从4通道到32通道，窗口大小8，跳跃间隔4，填空白2\n",
    "        self.conv1 = nn.Conv2d(4, 32, 8, 4, padding = 2)\n",
    "        # Pooling层，窗口2*2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 第二层卷积，从32通道到64通道，窗口大小4，跳跃间隔2，填空白1\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, 2, padding = 1)\n",
    "        # 第二个Pooling层，窗口2＊2，空白1\n",
    "        self.pool2 = nn.MaxPool2d(2, 2, padding = 1)\n",
    "        # 第三层卷积层，输入输出通道都是64，填空白为1\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1, padding = 1)\n",
    "        \n",
    "        # 最后有两层全链接层\n",
    "        self.fc_sz = 1600\n",
    "        self.fc1 = nn.Linear(self.fc_sz, 256)\n",
    "        self.fc2 = nn.Linear(256, ACTIONS)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入为一个batch的数据，每一个为前后相连的4张图像，每个图像为80*80的大小\n",
    "        # x的尺寸为：batch_size, 4, 80, 80\n",
    "        x = self.conv1(x)\n",
    "        # x的尺寸为：batch_size, 32, 20, 20\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # x的尺寸为：batch_size, 32, 10, 10\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # x的尺寸为：batch_size, 64, 5, 5\n",
    "        #x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # x的尺寸为：batch_size, 64, 5, 5\n",
    "        #x = self.pool2(x)\n",
    "        # 将x设为1600维的向量, batch_size, 1600\n",
    "        x = x.view(-1, self.fc_sz)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        readout = self.fc2(x)\n",
    "        return readout, x\n",
    "    def init(self):\n",
    "        # 初始化所有的网络权重\n",
    "        self.conv1.weight.data =  torch.abs(0.01 * torch.randn(self.conv1.weight.size()))\n",
    "        self.conv2.weight.data =  torch.abs(0.01 * torch.randn(self.conv2.weight.size()))\n",
    "        self.conv3.weight.data =  torch.abs(0.01 * torch.randn(self.conv3.weight.size()))\n",
    "        self.fc1.weight.data = torch.abs(0.01 * torch.randn(self.fc1.weight.size()))\n",
    "        self.fc2.weight.data = torch.abs(0.01 * torch.randn(self.fc2.weight.size()))\n",
    "        self.conv1.bias.data = torch.ones(self.conv1.bias.size()) * 0.01\n",
    "        self.conv2.bias.data = torch.ones(self.conv2.bias.size()) * 0.01\n",
    "        self.conv3.bias.data = torch.ones(self.conv3.bias.size()) * 0.01\n",
    "        self.fc1.bias.data = torch.ones(self.fc1.bias.size()) * 0.01\n",
    "        self.fc2.bias.data = torch.ones(self.fc2.bias.size()) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始在内存／GPU上定义一个网络\n",
    "use_cuda = torch.cuda.is_available() #检测本台机器中是否有GPU\n",
    "\n",
    "# 创建一个神经网络\n",
    "net = Net()\n",
    "# 初始化网络权重。之所以自定义初始化过程是为了增加神经网络权重的多样性\n",
    "net.init()\n",
    "# 如果有GPU，就把神经网络全部搬到GPU内存中做运算\n",
    "net = net.cuda() if use_cuda else net\n",
    "\n",
    "# 定义损失函数为MSE\n",
    "criterion = nn.MSELoss().cuda() if use_cuda else nn.MSELoss()\n",
    "# 定义优化器，并设置初始学习率维10^-6\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-6 )\n",
    "\n",
    "# 开启一个游戏进程，开始与游戏引擎通话\n",
    "game_state = GameState()\n",
    "\n",
    "# 学习样本的存储区域deque是一个类似于list的存储容器\n",
    "D = deque()\n",
    "\n",
    "# 状态打印log记录位置\n",
    "#a_file = open(\"logs_\" + GAME + \"/readout.txt\", 'w')\n",
    "#h_file = open(\"logs_\" + GAME + \"/hidden.txt\", 'w')\n",
    "\n",
    "# 将游戏设置为初始状态，并获得一个80*80的游戏湖面\n",
    "do_nothing = np.zeros(ACTIONS)\n",
    "do_nothing[0] = 1\n",
    "x_t, r_0, terminal = game_state.frame_step(do_nothing)\n",
    "x_t = cv2.cvtColor(cv2.resize(x_t, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "ret, x_t = cv2.threshold(x_t,1,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# 将初始的游戏画面叠加成4张作为神经网络的初始输入状态s_t\n",
    "s_t = np.stack((x_t, x_t, x_t, x_t), axis=0)\n",
    "\n",
    "# 设置初始的epsilon（采取随机行动的概率），并准备训练\n",
    "epsilon = INITIAL_EPSILON\n",
    "t = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 边做边学的核心算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该算法分为三个阶段：\n",
    "\n",
    "1、按照Epsilon贪婪算法采取一次行动；\n",
    "2、将选择好的行动输入给游戏引擎，得到下一帧的状态，并生成本帧的训练数据\n",
    "3、开始训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1000/ 状态 observe/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 4.510527e+00/ 轮得分 2.94\n",
      "时间步 2000/ 状态 observe/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 4.510527e+00/ 轮得分 2.73\n",
      "时间步 3000/ 状态 observe/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 4.510527e+00/ 轮得分 2.86\n",
      "时间步 4000/ 状态 observe/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 4.510527e+00/ 轮得分 2.91\n",
      "时间步 5000/ 状态 observe/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 4.510527e+00/ 轮得分 2.82\n",
      "时间步 6000/ 状态 observe/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 4.510527e+00/ 轮得分 2.84\n",
      "时间步 7000/ 状态 observe/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 4.510527e+00/ 轮得分 2.83\n",
      "时间步 8000/ 状态 observe/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 4.510527e+00/ 轮得分 2.78\n",
      "时间步 9000/ 状态 observe/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 4.510527e+00/ 轮得分 2.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 10000/ 状态 observe/ Epsilon 0.10/ 行动 0/ 奖励 0.1/ Q_MAX 4.510527e+00/ 轮得分 2.80\n",
      "时间步 11000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 3.800248e+00/ 轮得分 2.84\n",
      "损失函数： Variable containing:\n",
      " 0.7173\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "时间步 12000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 3.516031e+00/ 轮得分 2.91\n",
      "损失函数： Variable containing:\n",
      "1.00000e-03 *\n",
      "  8.7344\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "时间步 13000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 3.134146e+00/ 轮得分 2.98\n",
      "损失函数： Variable containing:\n",
      "1.00000e-03 *\n",
      "  9.1218\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "时间步 14000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 2.984318e+00/ 轮得分 3.03\n",
      "损失函数： Variable containing:\n",
      " 0.5046\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "时间步 15000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 2.840010e+00/ 轮得分 3.08\n",
      "损失函数： Variable containing:\n",
      " 1.3718\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "时间步 16000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 2.834957e+00/ 轮得分 3.12\n",
      "损失函数： Variable containing:\n",
      "1.00000e-03 *\n",
      "  8.2235\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "时间步 17000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 2.845603e+00/ 轮得分 3.16\n",
      "损失函数： Variable containing:\n",
      " 0.4626\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "时间步 18000/ 状态 explore/ Epsilon 0.10/ 行动 1/ 奖励 0.1/ Q_MAX 2.829625e+00/ 轮得分 3.20\n",
      "损失函数： Variable containing:\n",
      "1.00000e-03 *\n",
      "  9.0016\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 记录每轮平均得分的容器\n",
    "scores = []\n",
    "all_turn_scores = []\n",
    "while \"flappy bird\" != \"angry bird\":\n",
    "    # 开始游戏循环\n",
    "    ######################################################\n",
    "    ##########首先，按照贪婪策略选择一个行动 ##################\n",
    "    s = Variable(torch.from_numpy(s_t).type(torch.FloatTensor))\n",
    "    s = s.cuda() if use_cuda else s\n",
    "    s = s.view(-1, s.size()[0], s.size()[1], s.size()[2])\n",
    "    # 获取当前时刻的游戏画面，输入到神经网络中\n",
    "    readout, h_fc1 = net(s)\n",
    "    # 神经网络产生的输出为readout：选择每一个行动的预期Q值\n",
    "    readout = readout.cpu() if use_cuda else readout\n",
    "    # readout为一个二维向量，分别对应每一个动作的预期Q值\n",
    "    readout_t = readout.data.numpy()[0]\n",
    "\n",
    "    # 按照epsilon贪婪策略产生小鸟的行动，即以epsilon的概率随机输出行动或者以\n",
    "    # 1-epsilon的概率按照预期输出最大的Q值给出行动\n",
    "    a_t = np.zeros([ACTIONS])\n",
    "    action_index = 0\n",
    "    if t % FRAME_PER_ACTION == 0:\n",
    "        # 如果当前帧可以行动，则\n",
    "        if random.random() <= epsilon:\n",
    "            # 产生随机行动\n",
    "            #print(\"----------Random Action----------\")\n",
    "            action_index = random.randrange(ACTIONS)\n",
    "        else:\n",
    "            # 选择神经网络判断的预期Q最大的行动\n",
    "            action_index = np.argmax(readout_t)\n",
    "        a_t[action_index] = 1\n",
    "    else:\n",
    "        a_t[0] = 1 # do nothing\n",
    "\n",
    "    # 模拟退火：让epsilon开始降低\n",
    "    if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "\n",
    "    ######################################################################### \n",
    "    ##########其次，将选择好的行动输入给游戏引擎，并得到下一帧的状态 ################### \n",
    "    x_t1_colored, r_t, terminal = game_state.frame_step(a_t)\n",
    "    # 返回的x_t1_colored为游戏画面，r_t为本轮的得分，terminal为游戏在本轮是否已经结束\n",
    "    \n",
    "    # 记录一下每一步的成绩\n",
    "    scores.append(r_t)\n",
    "    if terminal:\n",
    "        # 当游戏结束的时候，计算一下本轮的总成绩，并将总成绩存储到all_turn_scores中\n",
    "        all_turn_scores.append(sum(scores))\n",
    "        scores = []\n",
    "    \n",
    "    # 对游戏的原始画面做相应的处理，从而变成一张80*80的，朴素的（无背景画面）的图\n",
    "    x_t1 = cv2.cvtColor(cv2.resize(x_t1_colored, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, x_t1 = cv2.threshold(x_t1, 1, 255, cv2.THRESH_BINARY)\n",
    "    x_t1 = np.reshape(x_t1, (1, 80, 80))\n",
    "    # 将当前帧的画面和前三帧的画面合并起来作为Agent获得的环境反馈结果\n",
    "    s_t1 = np.append(x_t1, s_t[:3, :, :], axis=0)\n",
    "    # 生成一个训练数据，分别将本帧的输入画面s_t,本帧的行动a_t，得到的环境回报r_t以及环境被转换的新状态s_t1存到D中\n",
    "    D.append((s_t, a_t, r_t, s_t1, terminal))\n",
    "    if len(D) > REPLAY_MEMORY:\n",
    "        # 如果D中的元素已满，则扔掉最老的一条训练数据\n",
    "        D.popleft()\n",
    "\n",
    "    ######################################################################### \n",
    "    ##########最后，当运行周期超过一定次数后开始训练神经网络 ################### \n",
    "    if t > OBSERVE:\n",
    "        # 从D中随机采样出一个batch的训练数据\n",
    "        minibatch = random.sample(D, BATCH)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 将这个batch中的s变量都分别存放到列表中\n",
    "        s_j_batch = [d[0] for d in minibatch]\n",
    "        a_batch = [d[1] for d in minibatch]\n",
    "        r_batch = [d[2] for d in minibatch]\n",
    "        s_j1_batch = [d[3] for d in minibatch]\n",
    "\n",
    "        # 接下来，要根据s_j1_batch，神经网络给出预估的未来Q值\n",
    "        \n",
    "        s = Variable(torch.FloatTensor(np.array(s_j1_batch, dtype=float)))\n",
    "        s = s.cuda() if use_cuda else s\n",
    "        readout, h_fc1 = net(s)\n",
    "        readout = readout.cpu() if use_cuda else readout\n",
    "        readout_j1_batch = readout.data.numpy()\n",
    "        # readout_j1_batch存储了一个minibatch中的所有未来一步的Q预估值\n",
    "        # 根据Q的预估值，当前的反馈r，以及游戏是否结束，更新待训练的目标函数值\n",
    "        y_batch = []\n",
    "        for i in range(0, len(minibatch)):\n",
    "            terminal = minibatch[i][4]\n",
    "            # 当游戏结束的时候，则用环境的反馈作为目标，否则用下一状态的Q值＋本期的环境反馈\n",
    "            if terminal:\n",
    "                y_batch.append(r_batch[i])\n",
    "            else:\n",
    "                y_batch.append(r_batch[i] + GAMMA * np.max(readout_j1_batch[i]))\n",
    "\n",
    "        # 开始梯度更新\n",
    "        y = Variable(torch.FloatTensor(y_batch))\n",
    "        a = Variable(torch.FloatTensor(a_batch))\n",
    "        s = Variable(torch.FloatTensor(np.array(s_j_batch, dtype=float)))\n",
    "        if use_cuda:\n",
    "            y = y.cuda()\n",
    "            a = a.cuda()\n",
    "            s = s.cuda()\n",
    "        # 计算s_j_batch的Q值\n",
    "        readout, h_fc1 = net(s)\n",
    "        readout_action = readout.mul(a).sum(1)\n",
    "        # 根据s_j_batch下所选择的预估Q和目标y的Q值的差来作为损失函数训练网络\n",
    "        loss = criterion(readout_action, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if t % 1000 == 0:\n",
    "            print('损失函数：', loss)\n",
    "       \n",
    "\n",
    "    # 将状态更新一次，时间步＋1\n",
    "    s_t = s_t1\n",
    "    t += 1\n",
    "\n",
    "    # 每隔 10000 次循环，存储一下网络\n",
    "    if t % 10000 == 0:\n",
    "        torch.save(net, 'saving_nets/' + GAME + '-dqn' + str(t) + '.txt')\n",
    "    \n",
    "    # 状态信息的转化，基本分为Observe，explore和train三个阶段\n",
    "    # Observe没有训练，explore开始训练，并且开始模拟退火，train模拟退火结束\n",
    "    state = \"\"\n",
    "    if t <= OBSERVE:\n",
    "        state = \"observe\"\n",
    "    elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "        state = \"explore\"\n",
    "    else:\n",
    "        state = \"train\"\n",
    "        \n",
    "    # 打印当前运行的一些基本数据，分别输出到屏幕以及log文件中\n",
    "    if t % 1000 == 0:\n",
    "        sss = \"时间步 {}/ 状态 {}/ Epsilon {:.2f}/ 行动 {}/ 奖励 {}/ Q_MAX {:e}/ 轮得分 {:.2f}\".format(\n",
    "            t, state, epsilon, action_index, r_t, np.max(readout_t), np.mean(all_turn_scores[-1000:]))\n",
    "        print(sss)\n",
    "        f = open('log_file.txt', 'a')\n",
    "        f.write(sss + '\\n')\n",
    "        f.close()\n",
    "    # write info to files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120a769b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open('final_log_file.txt', 'r')\n",
    "line = f.read().strip().split('\\n')\n",
    "values = []\n",
    "for ln in line:\n",
    "    segs = ln.split('/')\n",
    "    values.append(float(segs[-1].split(' ')[-1]))\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(values))*1000, values)\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Average Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net = torch.load('saving_nets/' + GAME + '-dqn' + str(2876000) + '.txt')\n",
    "net = torch.load('final_model.mdl')\n",
    "FINAL_EPSILON = 0.0001 # epsilon的最终值\n",
    "BATCH = 32 # 每一个批次的数据记录条数\n",
    "FRAME_PER_ACTION = 1 # 每间隔多少时间完成一次有效动作的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6053185c23ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2198\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2201\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1144\u001b[0;31m                 renderer, self, dsu, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2424\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2426\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1138\u001b[0m                                                                 renderer)\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval_contains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mupdate_position\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mstale\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale_callback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/learning_pytorch/lib/python3.5/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_stale_axes_callback\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_stale_axes_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 开始在内存／GPU上定义一个网络\n",
    "use_cuda = torch.cuda.is_available() #检测本台机器中是否有GPU\n",
    "\n",
    "# 如果有GPU，就把神经网络全部搬到GPU内存中做运算\n",
    "net = net.cuda() if use_cuda else net\n",
    "\n",
    "# 开启一个游戏进程，开始与游戏引擎通话\n",
    "game_state = GameState()\n",
    "\n",
    "# 状态打印log记录位置\n",
    "#a_file = open(\"logs_\" + GAME + \"/readout.txt\", 'w')\n",
    "#h_file = open(\"logs_\" + GAME + \"/hidden.txt\", 'w')\n",
    "\n",
    "# 将游戏设置为初始状态，并获得一个80*80的游戏湖面\n",
    "do_nothing = np.zeros(ACTIONS)\n",
    "do_nothing[0] = 1\n",
    "x_t, r_0, terminal = game_state.frame_step(do_nothing)\n",
    "x_t = cv2.cvtColor(cv2.resize(x_t, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "ret, x_t = cv2.threshold(x_t,1,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# 将初始的游戏画面叠加成4张作为神经网络的初始输入状态s_t\n",
    "s_t = np.stack((x_t, x_t, x_t, x_t), axis=0)\n",
    "\n",
    "# 设置初始的epsilon（采取随机行动的概率），并准备训练\n",
    "epsilon = FINAL_EPSILON\n",
    "t = 0# 记录每轮平均得分的容器\n",
    "scores = []\n",
    "all_turn_scores = []\n",
    "\n",
    "fig = plt.figure()\n",
    "axe = fig.add_subplot(111)\n",
    "dat = np.zeros((10, 10))\n",
    "img = axe.imshow(dat)\n",
    "while \"flappy bird\" != \"angry bird\":\n",
    "    # 开始游戏循环\n",
    "    ######################################################\n",
    "    ##########首先，按照贪婪策略选择一个行动 ##################\n",
    "    s = Variable(torch.from_numpy(s_t).type(torch.FloatTensor))\n",
    "    s = s.cuda() if use_cuda else s\n",
    "    s = s.view(-1, s.size()[0], s.size()[1], s.size()[2])\n",
    "    # 获取当前时刻的游戏画面，输入到神经网络中\n",
    "    readout, h_fc1 = net(s)\n",
    "    # 神经网络产生的输出为readout：选择每一个行动的预期Q值\n",
    "    readout = readout.cpu() if use_cuda else readout\n",
    "    # readout为一个二维向量，分别对应每一个动作的预期Q值\n",
    "    readout_t = readout.data.numpy()[0]\n",
    "\n",
    "    # 按照epsilon贪婪策略产生小鸟的行动，即以epsilon的概率随机输出行动或者以\n",
    "    # 1-epsilon的概率按照预期输出最大的Q值给出行动\n",
    "    a_t = np.zeros([ACTIONS])\n",
    "    action_index = 0\n",
    "    if t % FRAME_PER_ACTION == 0:\n",
    "        # 如果当前帧可以行动，则\n",
    "        if random.random() <= epsilon:\n",
    "            # 产生随机行动\n",
    "            #print(\"----------Random Action----------\")\n",
    "            action_index = random.randrange(ACTIONS)\n",
    "        else:\n",
    "            # 选择神经网络判断的预期Q最大的行动\n",
    "            action_index = np.argmax(readout_t)\n",
    "        a_t[action_index] = 1\n",
    "    else:\n",
    "        a_t[0] = 1 # do nothing\n",
    "    ######################################################################### \n",
    "    ##########其次，将选择好的行动输入给游戏引擎，并得到下一帧的状态 ################### \n",
    "    x_t1_colored, r_t, terminal = game_state.frame_step(a_t)\n",
    "    # 返回的x_t1_colored为游戏画面，r_t为本轮的得分，terminal为游戏在本轮是否已经结束\n",
    "    \n",
    "    # 记录一下每一步的成绩\n",
    "    scores.append(r_t)\n",
    "    if terminal:\n",
    "        # 当游戏结束的时候，计算一下本轮的总成绩，并将总成绩存储到all_turn_scores中\n",
    "        all_turn_scores.append(sum(scores))\n",
    "        scores = []\n",
    "    \n",
    "    # 对游戏的原始画面做相应的处理，从而变成一张80*80的，朴素的（无背景画面）的图\n",
    "    x_t1 = cv2.cvtColor(cv2.resize(x_t1_colored, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, x_t1 = cv2.threshold(x_t1, 1, 255, cv2.THRESH_BINARY)\n",
    "    x_t1 = np.reshape(x_t1, (1, 80, 80))\n",
    "    # 将当前帧的画面和前三帧的画面合并起来作为Agent获得的环境反馈结果\n",
    "    s_t1 = np.append(x_t1, s_t[:3, :, :], axis=0)\n",
    "    s_t = s_t1\n",
    "    t += 1\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    image = np.transpose(x_t1_colored, (1, 0, 2))\n",
    "    img.set_data(image)\n",
    "    img.autoscale()\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
